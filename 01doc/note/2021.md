## 源码



### threadLocal 和ineritableThreadLocal -	20210610

```java
    public void set(T value) {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null)
            // 当前的threadLocal对象为key,保存到线程的成员变量ThreadLocalMap中去
            map.set(this, value);
        else
            createMap(t, value); // t.threadLocals = new ThreadLocalMap(this, firstValue);
    }   


public T get() {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null) {
            /**
            To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys
            */
            ThreadLocalMap.Entry e = map.getEntry(this); // Entry是一个弱应用
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue(); // 初始化<Thread.currentThread(), null>，然后返回value: null
    }


      private Entry getEntry(ThreadLocal<?> key) {
          // 用当前threadLocal对象的hashcode和table进行取模计算下标
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.get() == key)
                return e;
            else
                return getEntryAfterMiss(key, i, e); // 发生hash碰撞后，并不是以链表形式去保存和取，而是取下标的后一位：nextIndex(i, len)
        }

public class InheritableThreadLocal<T> extends ThreadLocal<T> {}// 子线程可继承的ThreadLocal
    
//  Thread的init方法中：
  this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
// 再看看createInheritedMap：
return new ThreadLocalMap(parentMap);

// 实现可继承ThreadLocalMap的构造方法
  private ThreadLocalMap(ThreadLocalMap parentMap) {
      		// 根据父类ThreadLocalMap初始化子类的Table,就是一个Entry数组
            Entry[] parentTable = parentMap.table;
            int len = parentTable.length;
            setThreshold(len);
            table = new Entry[len];

            for (int j = 0; j < len; j++) {
                Entry e = parentTable[j];
                if (e != null) {
                    @SuppressWarnings("unchecked")
                    ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();
                    if (key != null) {
                        Object value = key.childValue(e.value); // return value; 这个key实际是InheritableThreadLocal, 实现了childValue,而ThreadLocal没有实现的。
                        Entry c = new Entry(key, value);
                        int h = key.threadLocalHashCode & (len - 1);
                        while (table[h] != null)
                            h = nextIndex(h, len);
                        table[h] = c;
                        size++;
                    }
                }
            }
        }

```

### String, StringBuffer和StringBuilder



> ```java
> public final class String
>     implements java.io.Serializable, Comparable<String>, CharSequence { // final修饰，表示不可继承
>     /** The value is used for character storage. */
>     private final char value[]; // 存储字符，final修饰，一旦赋值就不能重新引用对象
> 
>     /** Cache the hash code for the string */
>     private int hash; // Default to 0
> 
>     /**
>     String 是一个特殊的类：
>     1.使用“+” 拼接字符串时，jvm在编译时进行优化，如果是字符串常量拼接，编译后直接是拼接后的结果，如：
>     String value = "hello" + "world"; 编译后：String value = "helloworld";
>     如果不是常量拼接，编译后会转换成StringBuilder进行拼接：
>     String value = "count" + i; 编译后：String value = new StringBuilder("count").append(i);
>     
>     2. 如果直接String value = "helloworld";方式创建字符串，编译期间JVM就会到字符串常量池检查是否有字符串对象，没有就创建放到常量池，然后返回。
>     而    String value = new String("helloworld"); 编译期间检查字符串常量池中是否有“helloworld”，没有就创建。运行期间直接在堆中创建对象，然后返回堆中对象的引用。所以可能创建一个对象也可能两个。
>     
>     3.字符串常量池
>     jdk1.8前后有区别， 1.8之前常量池在永久代(permGen),1.8及之后再堆内存中。
>     顺便提一下，1.8之后永久代被元空间替代，跟堆内存在一起。
>     4.intern方法
>         intern方法的注释已经很好的说明了intern方法的执行逻辑：When the intern method is invoked, if the pool already contains a string equal to this object as determined by the equals method, then the string from the pool is returned. Otherwise, this object is added to the pool and a reference to this object is returned。All literal strings and string-valued constant expressions are interned。
>     简单翻译一下就是分以下三个情况：
>     1.执行intern方法时，如果字符串常量池中已经包含执行intern方法的String对象，则直接返回字符串常量池中的String对象；
>     2.执行intern方法时，如果字符串常量池中不包含执行intern方法的String对象，则先将该String对象添加到字符串常量池中，然后将字符串常量池中的String对象返回；
>     3.字符串字面常量（literal strings，如"a"，"b"）和字符串常量表达式（string-valued constant expressions，如"a" + "b"）也都要放到字符串常量池中。
>     随着虚拟机结构的调整，intern执行的结果在情况2下有些差异。Jdk1.6中的字符串常量池是放在永久代（Perm）区中的，永久代（Perm）区和正常的 JAVA堆（Heap ）区域是完全分开的。上面说过literal strings 和 string-valued constant expressions会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap区域。而Jdk1.8取消了永久代（Perm），字符串常量池就从 Perm 区移到正常的Java Heap 区域了。由于上面的调整，导致intern方法执行结果在jdk1.6和1.8下存在差异。
>     }
> 
>     private static void callInternMethodStringPoolNotExist() {
>         String value = String.valueOf('a');
>         String valueIntern = value.intern();
>         System.out.println(value == valueIntern);
>     }
>     Jdk1.8版本下，执行结果打印true。执行过程如下：
>     1.String value = String.valueOf('a')，'a'是primitive type，数据直接存储在栈上。然后再创建一个新的String对象value，value的内容为"a"，执行完常量池中并没有值为"a"的对象；（注意：如果直接String value = new String("c");执行首先检查常量池有没有，没有就创建，然后堆中创建一个对象）
>     2.执行String valueIntern = value.intern()，此时常量池里中还没有字符串"a"对象了，而Jdk1.8字符串常量池就在堆区，可以直接拿到value的引用，放到常量池中，然后返回value的引用，赋值给valueIntern；
>     3.System.out.println(value == valueIntern)，打印true，因为value和valueIntern都指向value的引用。*/
>     
>    
>    
> StringBuilder:
> public final class StringBuilder  extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 因为string是不可变的，所以提供可变的StringBuilder,来操作字符串
> public StringBuilder() { super(16);} // 默认的capacity是16
>     
> public StringBuilder(String str) { super(str.length() + 16);   append(str);} //始终保持16长度的空余 
>     
>  append方法：
>      public AbstractStringBuilder append(String str) {
>         if (str == null)
>             return appendNull();
>         int len = str.length();
>      	// 如果容量不够则创建足够容量的字符数组，然后通过System.arraycopy的方式填充
>         ensureCapacityInternal(count + len); 
>         str.getChars(0, len, value, count);
>         count += len;
>         return this;
>     }
>     
> StringBuffer:
> public final class StringBuffer    extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 跟StringBuilder一样都继承自AbstractStringBuilder类，但对几乎所有方法都进行重新加上了synchronized修饰方法
>         
> ```

### HashMap和LinkedHashMap

```java
public class HashMap<K,V> extends AbstractMap<K,V>    implements Map<K,V>, Cloneable, Serializable:
// 几个重要的成员变量
/**
   * The default initial capacity - MUST be a power of two.
   * 默认的容量，必须是2的次方：
   * 为了保证每个桶内的元素尽可能均匀的， 对添加的元素进行取模得到下标：h & (length-1)
   * 如果length不是2的次方如：10，假如现在有hash值为11和9，那么进行位运算结果：
   * 1011 & 1001 = 1001， 1001 & 1001 = 1001；
   * 而如果length是2的次方如：16，则同样对hash值为11和9进行取模结果：
   * 1011 & 1111 = 1011， 1001 & 1111 = 1001
   * 这样，有效避免了hash冲突，保证元素尽可能分布均匀
   *
   */
  static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

  /**
   * The maximum capacity, used if a higher value is implicitly specified
   * by either of the constructors with arguments.
   * MUST be a power of two <= 1<<30.
   */
  static final int MAXIMUM_CAPACITY = 1 << 30;

  /**
   * The load factor used when none specified in constructor.
   * 使用hash取模计算下标，元素分布的频率在hash桶中遵循一个泊松分布，然后0.75是泊松分布较理想的参数
   * 上面注释中还给了一个参考例子，当加载因子是0.75是，发生hash碰撞的桶的元素超过8个的概率为0.00000006几乎不可能。
   * 个人觉得从另一角度：
   * 如果加载因子是0.5那么会浪费一半的内存空间，加载因子是1，这样容量满了再去扩容，很容易造成hash冲突，导致链表过程影响查询效率
   * 所以0.75是一个折中的参数。
   */
  static final float DEFAULT_LOAD_FACTOR = 0.75f;

  /**
   *
   * 链表转成红黑树的阈值
   */
  static final int TREEIFY_THRESHOLD = 8;

  /**
   * 红黑树退化成链表的阈值
   */
  static final int UNTREEIFY_THRESHOLD = 6;

  /**
   * 当当前hash表的容量大于这个阈值时，才会进行链表转成红黑树操作
   * 否则只进行resize
   */
  static final int MIN_TREEIFY_CAPACITY = 64;

// put 方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
      boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 先判断是否为空
    if ((tab = table) == null || (n = tab.length) == 0)
      // 如果空就初始化
      n = (tab = resize()).length;
    // 判断插入的地方是否有人了
    if ((p = tab[i = (n - 1) & hash]) == null)
      // 没有人直接在末尾加入新节点
      tab[i] = newNode(hash, key, value, null);
    else {
      // 判断key是否一样
      Node<K,V> e; K k;
      if (p.hash == hash &&
          ((k = p.key) == key || (key != null && key.equals(k))))
        // 一样就就覆盖，更新操作
        e = p;
      // 不一样说明发生了hash碰撞，进一步判断这个桶是链表还是红黑树
      else if (p instanceof TreeNode)
        // 以红黑树方式添加
        e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
      else {
        // 以链表方式添加
        for (int binCount = 0; ; ++binCount) {
          if ((e = p.next) == null) {
            p.next = newNode(hash, key, value, null);
            // 如果链表长度大于阈值，转成红黑树
            if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
              // 里面进一步判断，如果整个表容量小于64就只进行rehash,不转换了
              treeifyBin(tab, hash);
            break;
          }
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            break;
          p = e;
        }
      }
      if (e != null) { // existing mapping for key
        V oldValue = e.value;
        if (!onlyIfAbsent || oldValue == null)
          e.value = value;
        afterNodeAccess(e);
        // 如果是覆盖就返回老的值
        return oldValue;
      }
    }
    // 最后添加完，判断是否需要resize
    ++modCount;
    if (++size > threshold)
      resize(); // 先扩容现容量的2倍，重新放置元素
    // 为了继承HashMap的LinkedHashMap类服务的
    afterNodeInsertion(evict);
    return null;
  }


// get 方法
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
      // 判断下标位置第一个元素是否符合key
      if (first.hash == hash && // always check first node
          ((k = first.key) == key || (key != null && key.equals(k))))
        // 是就返回第一个
        return first;
      if ((e = first.next) != null) {
        // 不是就接着往下找，判断桶如果是红黑树就用红黑树方式找，如果是链表就按链表找
        if (first instanceof TreeNode)
          return ((TreeNode<K,V>)first).getTreeNode(hash, key);
        do {
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            return e;
        } while ((e = e.next) != null);
      }
    }
    return null;
  }

public class LinkedHashMap<K,V>     extends HashMap<K,V>     implements Map<K,V>
    
 // 使用双向链表和重写了hashMap中3个方法保证顺序：
    // Callbacks to allow LinkedHashMap post-actions
    void afterNodeAccess(Node<K,V> p) { }
    void afterNodeInsertion(boolean evict) { }
    void afterNodeRemoval(Node<K,V> p) { }
    
 // put 方法： put方法没有重写HashMap的put方法，但是重新了其中的几个子的方法：
   Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
    LinkedHashMap.Entry<K,V> p =
        new LinkedHashMap.Entry<K,V>(hash, key, value, e);
    linkNodeLast(p);    // 加到双向链表的末尾
    return p;
  }

void afterNodeAccess(Node<K,V> e) { // move node to last将访问的元素放到链表最后
    
void afterNodeInsertion(boolean evict) { // possibly remove eldest， evict：是否删除旧元素
  LinkedHashMap.Entry<K,V> first;
    // removeEldestEntry给实现者来重写，有机会删除最老的元素，保持一定容量
  if (evict && (first = head) != null && removeEldestEntry(first)) { // removeEldestEntry：return false;
    K key = first.key;
    removeNode(hash(key), key, null, false, true);
  }
}
void afterNodeRemoval(Node<K,V> e) { // unlink remove方法中调用，删除链表中的元素
    
// 重写了get方法：
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
      return null;
    if (accessOrder) // 如果accessOrder为true,则开启LRU策略
      afterNodeAccess(e);
    return e.value;
  }
```

### ConcurrentHashMap

```java
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V> implements ConcurrentMap<K,V>, Serializable
    /**
    jdk1.8之前使用分段锁实现，即每个segment负责连续的几个桶，通过对segment加锁的方式实现线程安全，默认的支持并发写数量是16
    jdk1.8通过CAS + syncronized实现并发
    */

/**
   * The default concurrency level for this table. Unused but
   * defined for compatibility with previous versions of this class.
   * 默认支持多少线程进行并发写，在jdk1.7及之前使用segment设计时使用，现在没用了。
   */
  private static final int DEFAULT_CONCURRENCY_LEVEL = 16;

  /**
   * 默认加载因子，同HashMap
   */
  private static final float LOAD_FACTOR = 0.75f;

  /**
   * 默认树化的阈值，同HashMap
   */
  static final int TREEIFY_THRESHOLD = 8;

  /**
   * 默认退化链表的阈值，同HashMap
   */
  static final int UNTREEIFY_THRESHOLD = 6;

  /**
   * 树化的表容量阈值，小于就只进行resize
   */
  static final int MIN_TREEIFY_CAPACITY = 64;


public V remove(Object key)
remove方法跟put方法过程差不多，调用replaceNode方法，先判断是否正在resize,如果是当前线程就进入helpTransfer方法
否则直接使用synchronized加锁，删除成功后，调用addCount(-1, -1)方法计数字。
    
    /** Implementation for put and putIfAbsent */
  /**
   *  如果是第一次put,需要初始化表
   *  如果put位置桶空的，则通过CAS添加新节点
   *  如果put位置桶不为空，但hash状态==MOVED(-1),说明当前表正在进行resize,当前线程进入helpTransfer方法
   *  如果put位置桶不为空，说明桶已经有人了，对当前的桶进行加锁
   *    判断是链表还是红黑树，用对应的方法去添加
   *      如果有相同key则覆盖
   *      没有相同key,添加新节点到后面
   * 调用addCount(int count, int check),count表示新增元素个数，check是链表的长度. 计算并且检查是否需要resize
   */
  final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode()); // 对hashCode再hash,减少hash碰撞
    int binCount = 0; // 统计链表元素个数，判断是否要转成红黑树
    for (Node<K,V>[] tab = table;;) {
      Node<K,V> f; int n, i, fh;
      // 懒加载，第一次put时，初始化表，避免第一次操作就进行resize影响效率，如：putAll
      if (tab == null || (n = tab.length) == 0)
        tab = initTable();
        // 查找桶，是否为空,tabAt内部直接调用UNSAFE.getObjectVolatile获取主内存中的值
      else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
        // 添加空的桶，直接CAS,无需加锁
        if (casTabAt(tab, i, null,
            new Node<K,V>(hash, key, value, null)))
          break;                   // no lock when adding to empty bin
      }
      // hash 为-1，说明当前表状态是正在扩容
      else if ((fh = f.hash) == MOVED)
        // 帮助扩容
        tab = helpTransfer(tab, f);
      else {
        V oldVal = null;
        synchronized (f) { // 要存的桶里已经有人了，对当前桶加锁
          if (tabAt(tab, i) == f) {
            if (fh >= 0) {
              binCount = 1;
              // 如果是链表，以链表方式添加
              for (Node<K,V> e = f;; ++binCount) {
                K ek;
                if (e.hash == hash &&
                    ((ek = e.key) == key ||
                        (ek != null && key.equals(ek)))) {
                  oldVal = e.val;
                  // key是同一个，是否覆盖
                  if (!onlyIfAbsent)
                    e.val = value;
                  break;
                }
                // 不是同一个key,新值加到链表最后
                Node<K,V> pred = e;
                if ((e = e.next) == null) {
                  pred.next = new Node<K,V>(hash, key,
                      value, null);
                  break;
                }
              }
            }
            // 如果是红黑树，以红黑树方式添加
            else if (f instanceof TreeBin) {
              Node<K,V> p;
              binCount = 2;
              if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                  value)) != null) {
                oldVal = p.val;
                if (!onlyIfAbsent)
                  p.val = value;
              }
            }
          }
        }
        if (binCount != 0) {
          // 判断链表是否需要转成红黑树
          if (binCount >= TREEIFY_THRESHOLD)
            treeifyBin(tab, i);
          if (oldVal != null)
            return oldVal;
          break;
        }
      }
    }
    // 参数1表示增加表个数，binCount（链表长度）参数表示是否需要进行resize检查
    addCount(1L, binCount);
    return null;
  }

/**
   * Helps transfer if a resize is in progress.
   * 判断表不为空，并且状态是-1，正在转移
   * 判断正在扩容，并且扩容线程是否满了
   * 通过CAS设置扩容的线程数量+1
   * 调用transfer方法，进行扩容
   */
  final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {
    Node<K,V>[] nextTab; int sc;// 并发扩容的线程数量
    //如果tab不为空并且节点是正在转移的节点
    if (tab != null && (f instanceof ForwardingNode) &&
        (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {
      // 获取表length获取一个标识
      int rs = resizeStamp(tab.length);
      // 判断nextTab和tab都没有并发修改，并且sizeCtl < 0说明还在扩容
      while (nextTab == nextTable && table == tab &&
          (sc = sizeCtl) < 0) {
        // 判断sizeCtl标识符号，不在变化了，扩容结束了，达到最大扩容线程了或者转移下标在<0,扩容结束
        if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
            sc == rs + MAX_RESIZERS || transferIndex <= 0)
          break;
        // 通过CAS,扩容线程+1
        if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
          // 进行转移
          transfer(tab, nextTab);
          break;
        }
      }
      return nextTab;
    }
    return table;
  }


  /**
   * Moves and/or copies the nodes in each bin to new table. See
   * above for explanation.
   * 根据cpu个数，配置的最小步数：16和表长度计算步长，即每次转移多少节点
   * 初始化一个长度为原来2倍的数组
   * 进行转移
   */
  private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;
    // 根据cpu个数和配置的步长（即每次转移多少个节点）计算步长
    // 公式：如果cpu个数>1,步长为表/8/cpu个数，这个结果小于最小值，则用最小值
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
      stride = MIN_TRANSFER_STRIDE; // subdivide range
    if (nextTab == null) {            // initiating
      try {
        @SuppressWarnings("unchecked")
        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];// 创建一个原来大小2倍的数组
        nextTab = nt;
      } catch (Throwable ex) {      // try to cope with OOME
        sizeCtl = Integer.MAX_VALUE;
        return;
      }
      nextTable = nextTab;
      transferIndex = n;
    }
    int nextn = nextTab.length;
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) {
      Node<K,V> f; int fh;
      while (advance) {
        int nextIndex, nextBound;
        if (--i >= bound || finishing)
          advance = false;
        else if ((nextIndex = transferIndex) <= 0) {
          i = -1;
          advance = false;
        }
        else if (U.compareAndSwapInt
            (this, TRANSFERINDEX, nextIndex,
                nextBound = (nextIndex > stride ?
                    nextIndex - stride : 0))) {
          bound = nextBound;
          i = nextIndex - 1;
          advance = false;
        }
      }
      if (i < 0 || i >= n || i + n >= nextn) {
        int sc;
        if (finishing) {
          nextTable = null;
          table = nextTab;
          sizeCtl = (n << 1) - (n >>> 1); // 转移完成，设置原表大小的0.75
          return;
        }
        if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
          if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
            return;
          finishing = advance = true;
          i = n; // recheck before commit
        }
      }
      else if ((f = tabAt(tab, i)) == null)
        advance = casTabAt(tab, i, null, fwd);
      else if ((fh = f.hash) == MOVED)
        advance = true; // already processed
      else {
        synchronized (f) {
          if (tabAt(tab, i) == f) {
            Node<K,V> ln, hn;
            if (fh >= 0) {
              int runBit = fh & n;
              Node<K,V> lastRun = f;
              for (Node<K,V> p = f.next; p != null; p = p.next) {
                int b = p.hash & n;
                if (b != runBit) {
                  runBit = b;
                  lastRun = p;
                }
              }
              if (runBit == 0) {
                ln = lastRun;
                hn = null;
              }
              else {
                hn = lastRun;
                ln = null;
              }
              for (Node<K,V> p = f; p != lastRun; p = p.next) {
                int ph = p.hash; K pk = p.key; V pv = p.val;
                if ((ph & n) == 0)
                  ln = new Node<K,V>(ph, pk, pv, ln);
                else
                  hn = new Node<K,V>(ph, pk, pv, hn);
              }
              setTabAt(nextTab, i, ln);
              setTabAt(nextTab, i + n, hn);
              setTabAt(tab, i, fwd);
              advance = true;
            }
            else if (f instanceof TreeBin) {
              TreeBin<K,V> t = (TreeBin<K,V>)f;
              TreeNode<K,V> lo = null, loTail = null;
              TreeNode<K,V> hi = null, hiTail = null;
              int lc = 0, hc = 0;
              for (Node<K,V> e = t.first; e != null; e = e.next) {
                int h = e.hash;
                TreeNode<K,V> p = new TreeNode<K,V>
                    (h, e.key, e.val, null, null);
                if ((h & n) == 0) {
                  if ((p.prev = loTail) == null)
                    lo = p;
                  else
                    loTail.next = p;
                  loTail = p;
                  ++lc;
                }
                else {
                  if ((p.prev = hiTail) == null)
                    hi = p;
                  else
                    hiTail.next = p;
                  hiTail = p;
                  ++hc;
                }
              }
              ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                  (hc != 0) ? new TreeBin<K,V>(lo) : t;
              hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                  (lc != 0) ? new TreeBin<K,V>(hi) : t;
              setTabAt(nextTab, i, ln);
              setTabAt(nextTab, i + n, hn);
              setTabAt(tab, i, fwd);
              advance = true;
            }
          }
        }
      }
    }
  }
```



## 算法

### 栈，堆和二叉树

#### 94二叉树的中序遍历

实现方式：递归，迭代（栈），这里用栈实现

#### 155最小栈

两个栈实现，一个保存数据，一个保存最小记录		--ok

### 链表

### 动态规划

