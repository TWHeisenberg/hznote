# 安装虚拟机和搭建环境

## 安装centos(7.4)

## 配置网络

	[root@vm01-192 ~]# vim /etc/sysconfig//network-scripts/ifcfg-ens33
	TYPE=Ethernet
	PROXY_METHOD=none
	BROWSER_ONLY=no
	DEFROUTE=yes
	IPV4_FAILURE_FATAL=no
	IPV6INIT=yes
	IPV6_AUTOCONF=yes
	IPV6_DEFROUTE=yes
	IPV6_FAILURE_FATAL=no
	IPV6_ADDR_GEN_MODE=stable-privacy
	NAME=ens33
	DEVICE=ens33
	# 主要修改下面的配置
	BOOTPROTO=static
	ONBOOT=yes
	IPADDR=192.168.198.101
	GATEWAY=192.168.198.2
	NETMASK=255.255.255.0
	# 配置域名服务器
	DNS1=8.8.8.8
	DNS2=8.8.4.4

## 配置yum源

```sh
# 备份并移除老的repo
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo

yum clean all
yum makecache
```
## 基础配置，关闭防火墙，配置ssh等

### 配置ssh

```shell
# 生成公钥
ssh-keygen -o
# 复制公钥
ssh-copy-id vm01
```
### 关闭防火墙

```shell
# 停止防火墙
systemctl stop firewalld.service
# 查看状态
systemctl status firewalld.service
# 永久关闭
systemctl disable firewalld.service
```
### 配置ntp

​	TODO

### 关闭SELinux

```shell
# 查看状态
/usr/sbin/sestatus -v
# 关闭,disable掉
vim /etc/selinux/config
# 改成SELINUX=disabled
```


# 搭建hadoop集群



## 安装zookeeper

```shell
# 下载并解压zk压缩包
tar -zxvf zookeeper-3.4.8.tar.gz  -C /opt
cd /opt && ln -s  zookeeper-3.4.8 zookeeper

# 修改配置
vim conf/zoo.cfg
# 配置如下：
dataDir=/opt/zookeeper/data
dataLogDir=/opt/zookeeper/logs
clientPort=2181
server.1=vm01:2888:3888

# 配置myid
echo 1 > /opt/zookeeper/data/myid

#启动
bash bin/zkServer.sh start

# 确认
bash bin/zkServer.sh status
# 看到下面结果：
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: standalone
```



## 安装hadoop

```shell
# 下载并解压

# 修改配置文件
core-site.xml
yarn-site.xml
mapred-site.xml
hdfs-site.xml
slaves
hadoop-env.sh # 配置JAVA_HOME

# 格式化hdfs的namenode
hadoop namenode -format
# 启动namenode
hadoop-daemon.sh start namenode
# 确认日志
tail -f /opt/hadoop/logs *.log

# 如果启动HA(两个namenode)
    # 在namenode2机器上同步
    hadoop namenode -bootstrapStandby
    # 启动zkfc
    hadoop-daemon.sh start zkfc
    # 这时两个节点一个standby一个active

# 启动secondarynamenode
hadoop-daemon.sh start secondarynamenode

# 启动datanode
hadoop-daemons.sh start datanode

# 启动yarn
start-yarn.sh

tips:
# 启动hdfs
start-dfs.sh
# 关闭hdfs
stop-dfs.sh
# 启动zkclient，并连接zookeeper集群
/opt/zookeeper/bin/zkCli.sh -server master:2181,slave1:2181,slave2:2181
# 启动yarn
start-yarn.sh
	#  	yarn，单独启动的方式
		yarn-daemon.sh start resourcemanager
# 查看zk状态
/opt/zookeeper/bin/zkServer.sh status
# hdfs ui界面
http://192.168.198.101:50070/dfshealth.html#tab-overview
# yarn ui界面
http://192.168.198.101:8088/

# hbase ui界面
http://192.168.198.101:60010/master-status#compactStas
# 关闭集群hbase：
stop-hbase.sh
# 启动/关闭hbase所有：
hbase-daemons.sh start/stop regionserver
# 开启、关闭hbase单独
hbase-daemon.sh start/stop regionserver
hbase-daemon.sh start/stop master


# jps
24912 ResourceManager
24625 NameNode
25106 NodeManager
28962 QuorumPeerMain
25507 SecondaryNameNode
24788 DataNode
34907 HMaster
35934 Jps

```

## 安装hbase

```shell
# 下载并解压安装包
tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt
# 创建软连接
cd /opt && ln -s hbase-1.3.1-bin.tar.gz hbase 
# 修改配置
hbase-site.xml
regionservers
hbase-env.sh # 配置JAVA_HOME
	# 配置zk
    export HBASE_MANAGES_ZK=true # 通过hbase来管理zk,但如果是外部的zk就不能让hbase来管理
    export HBASE_PID_DIR=/opt/data/hbase
# 通过hbase启动zk
hbase-daemons.sh start zookeeper
# 启动
start-hbase.sh
# 查看日志确认，jps
# hbase shell

# 启动集群
	# 先启动zk
	bash /opt/zookeeper/bin/zkServer.sh start
	bash /opt/zookeeper/bin/zkServer.sh status
	# 启动hadoop
	hadoop-daemon.sh start namenode
	hadoop-daemon.sh start secondarynamenode
	hadoop-daemon.sh start datanode
	# 启动hbase
	start-hbase.sh
	# 如果是c++去连接，hbase默认支持java去连接，如果是c++要启动thrift2,端口默认是9090
	hbase-deamon.sh start thrift2

```

## 安装mysql

```shell
# 如果安装过，先卸载
rpm -qa | grep mysql
rpm -e mysql　　// 普通删除模式
rpm -e --nodeps mysql　　// 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除

# 下载资源包
wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm
rpm -ivh mysql-community-release-el7-5.noarch.rpm
yum update
yum install mysql-server
# 权限设置
chown mysql:mysql -R /var/lib/mysql
# 初始化mysql
mysqld --initialize
# 启动mysql
systemctl start mysqld
# 查看mysql运行状态
systemctl status mysqld
# 登录查看确认正常只用
mysql
SHOW DATABASES;
 # 默认的root用户密码为空，你可以使用次命令来创建root用户的密码
mysqladmin -u root password "root";
	# 如果有以下报错，可以尝试手动修改密码：mysqladmin: connect to server at 'localhost' failed
	systemctl stop mysqld.service # 停止mysql
	mysqld_safe --skip-grant-tables & # 安全模式启动
	mysql -uroot -p # 无密码登录
	use mysql;
	update user set password=password("root") where user='root' and host='localhost'; # 修改密码
	flush privileges; # 刷新
	quit
	# 杀掉安全模式的mysql,然后重新启动一下
	systemctl status mysqld.service
```

## 安装hive

```shell 
# 下载并解压安装包
tar -zxvf apache-hive-2.3.8-bin.tar.gz -C /opt
# 创建软连接
ln -s /opt/apache-hive-2.3.8-bin /opt/hive 
# 修改配置，hive-site.xml,主要是配置保存元数据的数据库
# hive内置derby数据库，如果使用mysql,在mysql安装完成前提，修改连接配置
# 查看hive安装
hive --version
Hive 2.3.8
	Git git://chaos-mbp.lan/Users/chao/git/hive -r f1e87137034e4ecbe39a859d4ef44319800016d7
	Compiled by chao on Thu Jan 7 11:36:26 PST 2021
	From source with checksum 2992381e2a287352c65262bf40d3f932
# 初始化
schematool -initSchema -dbType derby # 不执行这步骤，hive 执行报错：org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
	# 如果初始化执行报错：FUNCTION 'NUCLEUS_ASCII' already exists，要把目录删除线
	mv metastore_db metastore_db.bak
# 确认安装成功：
hive> show databases;
OK
default
Time taken: 4.961 seconds, Fetched: 1 row(s)

# 通过beeline连接
	 hiveserver2 # 启动hiveserver
	 beeline # 启动beeline
     !connect jdbc:hive2://192.168.198.101:10000/hive # 连接
```

## hbase和hive集成

```shell
# 拷贝hbase的jar包到hive lib下


# 创建关联表
CREATE EXTERNAL TABLE if not exists hznc_mkdata_tickdata(
rowkey string,
01cSymbol string,
02dbClosePrice double,
03dbHeightPrice double,
04dbLowPrice double,
05dbOpenPrice double,
06dbSum int,
07dbYTClosePrice double,
08uTime bigint,
09uVolume bigint,
10uVolumeSell bigint,
11zpos double,
12zposdiff double,
13avgPrice double,
`from` string) 
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' 
WITH SERDEPROPERTIES('hbase.columns.mapping' = ':key,cf_data:01cSymbol,cf_data:02dbClosePrice,cf_data:03dbHeightPrice,cf_data:04dbLowPrice,cf_data:05dbOpenPrice,cf_data:06dbSum,cf_data:07dbYTClosePrice,cf_data:08uTime,cf_data:09uVolume,cf_data:10uVolume_Sell,cf_data:11zpos,cf_data:12zpos_diff,cf_data:13avgPrice,cf_data:from') TBLPROPERTIES('hbase.table.name' = 'hznc_mkdata:tickdata');

# 注意，表名不能带有“:”， long类型在hive中对呀bigint

# 模糊查询
select * from hznc_mkdata_tickdata where 01csymbol like concat("%", "IC", "%") ;
# 常用的操作，哪些会触发mr任务？
# WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
```



## 问题

```
java.io.IOException: Incompatible clusterIDs in /opt/hadoop-data/dfs/data
解决：
执行hdfs namenode -format后，current目录会删除并重新生成，其中VERSION文件中的clusterID也会随之变化，而datanode的VERSION文件中的clusterID保持不变，造成两个clusterID不一致。

  所以为了避免这种情况，可以再执行的namenode格式化之后，删除datanode的current文件夹，或者修改datanode的VERSION文件中出clusterID与namenode的VERSION文件中的clusterID一样，然后重新启动dfs。
```

```
RROR: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet

关闭hadoop的安全模式：
hdfs dfsadmin -safemode get
hdfs dfsadmin -safemode leave
# 重启hbase
```

```
maven 编译报错：
java.lang.ArrayIndexOutOfBoundsException: 8377
        at org.codehaus.plexus.util.xml.pull.MXParser.parsePI(MXParser.java:2502)
 
 升级maven试试

```

```
报错：
网络不通，ifconfig 查看网卡没有起来
service network restart 查看报错：
Failed to start LSB: Bring up/down networking.

查看日志：cat /var/log/message

rtnetlink answers: file exists

原因：
NetworkManager 服务和network冲突了，关掉前者
service NetworkManager stop # systemctl stop NetworkManager
chkconfig NetworkManager off # 禁止开机启动

# 重启网络
service network restart
```

```
beeline连接报错：
Error: Could not open client transport with JDBC Uri: jdbc:hive2://192.168.198.101:10000/hive: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate root (state=08S01,code=0)
解决: 在hadoop配置core-site.xml中添加：

<property>
<name>hadoop.proxyuser.root.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.root.groups</name>
<value>*</value>
</property>
# 重启
```

```
hbase scan setCaching 和setBatch区别：
scan可以通过setCaching与setBatch方法提高速度（以空间换时间）；
scan中的setCaching与setBatch方法的区别是什么呢？

setCaching设置的值为每次rpc的请求记录数，默认是1；cache大可以优化性能，但是太大了会花费很长的时间进行一次传输。
setBatch设置每次取的column size；有些row特别大，所以需要分开传给client，就是一次传一个row的几个column。
batch和caching和hbase table column size共同决意了rpc的次数。

```

