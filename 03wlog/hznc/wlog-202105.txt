## tips

注意：

夜盘数据比较特殊,  比如 2021-04-01 21:00:00 ~ 2021-04-02 00:00:00 的数据, 其实是 2021-03-31 21:00:00 ~ 2021-04-01 00:00:00 的数据.  即夜盘一整天的开盘时间是 昨天 21:00

maven 官方下载地址：

https://archive.apache.org/dist/maven/maven-3/

服务器地址：

```
10.10.10.104   administrator  Admin123
10.10.10.102 administrator  Admin711406
```



项目 SVN 地址:
https://10.10.10.102/svn/量化系统/nc_tree_parse/nc_algo

confluence 地址：http://10.10.0.47:8090/

​	ftp:list_delete_rowkey.shb

	   历史股指期权 和 商品期权 数据的下载地址 ：
	   域名：tik-ftp.citicsf.com 端口：8371
	   电信IP：58.33.80.163     端口：8371
	   联通IP：140.206.97.123 端口：8371
	   李佳桧/83g3Mh7m

​	历史数据：

​		50ETF期权数据
​		CFFEX股指期货
​		DCE大连商品
​		CZC3郑州商品
​		SHFE上海商品

钉钉邮箱：wangdao6551@dingtalk.com

jira账号：u00479/123456

jira   ip地址更换成：http://10.10.0.47:8080/

svn账号和密码：liuzhenjiang/liuzhenjiang

hbase:
	hadoop-daemon.sh start datanode
	hbase-daemon.sh start regionserver
	tail  -n -500 /usr/local/hbase/logs/hbase-hadoop-regionserver-slave4.log

sql server:
		properties.setProperty("user", "R16");
		properties.setProperty("password", "R16_0625");

现有集群规模：共有七台机器，老机房两台，新机房五台。

老机房两台：

​     主机名：keep-0        IP：10.10.10.110    nc_007用户登录密码：nc_007

主机名：keep-1        IP：10.10.10.111       nc_008用户登录密码：nc_008

 ![image-20210510085345685](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210510085345685.png)

新机房五台：

​     主机名：master      IP：10.10.0.254        root用户登录密码：1

主机名：slave1        IP：10.10.0.119        root用户登录密码：1

主机名：slave2        IP：10.10.0.54        root用户登录密码：1

主机名：slave3        IP：10.10.0.253        hadoop用户登录密码：1

主机名：slave4        IP：10.10.0.252        hadoop用户登录密码：1

 

集群配置：

​     三台zookeeper，七台HDFS（master，slave1，上运行namenode，七台DataNode）

​     Master，slave3作为HBASE的HMaster节点，除master节点之外，六台起HRegionserver服务，HMaster节点需要另起ThriftServer服务来提供读取数据服务。集群启动步骤见《集群各项服务启动命令.txt》文件

Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas

HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview



git key: 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



## 每天做的

```
1.检查下hadoop集群, hbase集群
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi，
    	  
10.10.10.102 administrator/Admin711406  
	进程：GetMarketDataAndStore
	     GuPiaoReduce（RunDataMerge?）
```





## 20210506

1.每天上班要做的

```
1.检查下hadoop集群, hbase集群		--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406  
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
	     GetMarketDataAdnStore 有两个进程在跑？ 关掉一个		--ok
```



2.k线程序继续开发啊

​		继续优化：多线程去做			--ok

​		tick数据：

2021/05/06 10:59:21 INFO  [store-tick] - store tick: IC05_1620269959 ok, count: 1

1170: 2021/05/06 11:04:33 INFO  [store-tick] - store tick: IC05_1620270271 ok, count: 600

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1620269959", ENDROW => "IC05_1620270271"}



1s:		--ok

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620281281", ENDROW => "IC05_1620283799"}

1: 77:2021/05/06 14:08:03 INFO  [mergeAndstore-kline-1] - put kline IC05_1620281281 to hznc_mkdata:1sdata ok

88380:2021/05/06 14:50:00 INFO  [mergeAndstore-kline-1] - put kline IC05_1620283799 to hznc_mkdata:1sdata ok



5s:			--ok

put kline IC05_1620281281 to hznc_mkdata:5sdata ok

IC05_1620284100 to hznc_mkdata:5sdata

scan "hznc_mkdata:5sdata", {STARTROW => "IC05_1620281281", ENDROW => "IC05_1620284100"}



1min:		--ok

put kline IC05_1620281281 to hznc_mkdata:1mindata ok

pkline IC05_1620284040 to hznc_mkdata:1mindata

scan "hznc_mkdata:1mindata", {STARTROW => "IC05_1620281281", ENDROW => "IC05_1620284040"}



```

hbase(main):005:0> get "hznc_mkdata:1sdata", "IC05_1620270342"
COLUMN                                                       CELL
 cf_data:01cSymbol                                           timestamp=1620270344250, value=IC05
 cf_data:02dbClosePrice                                      timestamp=1620270344250, value=6421.6
 cf_data:03dbHeightPrice                                     timestamp=1620270344250, value=6421.6
 cf_data:04dbLowPrice                                        timestamp=1620270344250, value=6421.6
 cf_data:05dbOpenPrice                                       timestamp=1620270344250, value=6421.6
 cf_data:06dbSum                                             timestamp=1620270344250, value=5137280.0
 cf_data:07dbYTClosePrice                                    timestamp=1620270344250, value=6477.6
 cf_data:08uTime                                             timestamp=1620270344250, value=1620270342
 cf_data:09uVolume                                           timestamp=1620270344250, value=4
 cf_data:10uVolume_Sell                                      timestamp=1620270344250, value=35561
 cf_data:11zpos                                              timestamp=1620270344250, value=66098.0
 cf_data:12zpos_diff                                         timestamp=1620270344250, value=-4.0
 cf_data:13avgPrice                                          timestamp=1620270344250, value=6486.400000000001
1 row(s) in 0.0320 seconds
```



​		主力数据				--ok

​		打包， 定时脚本， cron

​	

​		测试发送结果



​		继续测试

​		上传到git?



3. 补一下k线数据

   4.26日的

   ​	查询一下线上多少条，本地的数据多少条，tick是否需要补

2021/4/26,09:30:00

date  -d "2021-4-26 09:30:00" +%s

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1619400600_0", ENDROW => "IC05_1619420400_1"}

IC， 11:10 - 11:25少了

date  -d "2021-4-26 11:10:00" +%s     1619406600

date  -d "2021-4-23 11:10:00" +%s     1619147400

get "hznc_mkdata:5mindata", "IC05_1619406600"

scan "hznc_mkdata:5mindata", {STARTROW => "IC05_1619141400", ENDROW => "IC05_1619161200"}	正常48条

scan "hznc_mkdata:5mindata", {STARTROW => "IC05_1619400600", ENDROW => "IC05_1619420400"}		40条

​		date  -d "2021-4-23 09:30:00" +%s     1619141400

​		date  -d "2021-4-23 15:00:00" +%s	1619161200



 cf_data:01cSymbol                                           timestamp=1617240602523, value=IC05
 cf_data:02dbClosePrice                                      timestamp=1617240602523, value=6182.8
 cf_data:03dbHeightPrice                                     timestamp=1617240602523, value=6182.8
 cf_data:04dbLowPrice                                        timestamp=1617240602523, value=6182.8
 cf_data:05dbOpenPrice                                       timestamp=1617240602523, value=6182.8
 cf_data:06dbSum                                             timestamp=1617240602523, value=2473600.0
 cf_data:07dbYTClosePrice                                    timestamp=1617240602523, value=6176.2
 cf_data:08uTime                                             timestamp=1617240602523, value=1617240600
 cf_data:09uVolume                                           timestamp=1617240602523, value=2
 cf_data:10uVolume_Sell                                      timestamp=1617240602523, value=2
 cf_data:11zpos                                              timestamp=1617240602523, value=4161.0
 cf_data:12zpos_diff                                         timestamp=1617240602523, value=4161.0
 cf_data:13avgPrice                                          timestamp=1617240602523, value=0.0



{"symbol":"IC05","utime:1617240600100,当前成交量:2,当前成交额:2473600.0,高:6185.2,低:6182.8,当前开:6182.8,当前收:6182.8,今量:2,今额:2473600.0,今持仓:4161.0,今开:6185.2,今收:6182.8,今均:6182.8,交易日:20210401,}



```
tickCycle		56420
kCycle			50

kBuff.Timestamp 1619712 时间戳不对

对比下1s数据：
2021/04/30 13:29:53 INFO  [main] - put kline IC09_1619760592 to hznc_mkdata:1sdata ok
2021/04/30 13:29:53 INFO  [main] - put kline IC12_1619760592 to hznc_mkdata:1sdata ok


2021/04/30 13:38:35 INFO  [main] - put kline IC06_1619761110 to hznc_mkdata:5sdata ok

几个字段不对：
 cf_data:09uVolume                                           timestamp=1619761117066, value=0
 cf_data:06dbSum                                             timestamp=1619761117066, value=0
 cf_data:12zpos_diff                                         timestamp=1619761117066, value=0



	行 5262: 2021/04/30 14:25:01 INFO  [main] - put kline IC05_1619763600 to hznc_mkdata:5mindata ok
	行 5973: 2021/04/30 14:30:01 INFO  [main] - put kline IC05_1619763900 to hznc_mkdata:5mindata ok
	行 6641: 2021/04/30 14:35:01 INFO  [main] - put kline IC05_1619764200 to hznc_mkdata:5mindata ok
	行 7322: 2021/04/30 14:40:00 INFO  [main] - put kline IC05_1619764500 to hznc_mkdata:5mindata ok
	
	
	2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245932 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245933 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245934 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245935 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245942 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245944 to hznc_mkdata:1sdata ok
2021/04/30 15:54:57 INFO  [main] - put kline IC05_1617245950 to hznc_mkdata:1sdata ok
	
	
	
	问题：
	06dbSum   hbase中是累积的成交额还是差值，即减去上一个tick的？
	09uVolume	当前成交量，hbase总是累积的成交量还是差值？
	03dbHeightPrice	取Math.Max(open, last) ? 还是last?
	12zpos_diff	持仓量，相减的。
```



代码考一份出去

.c文件.h文件



昨日结算价：

ic:6443.0

if:5119.4

IH:3515.6

不清空了，直接补发

## 20210507

1.每天上班要做的

```
1.检查下hadoop集群, hbase集群			--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
2.检查程序运行和发送情况		--ok
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406  		--ok
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
	     GetMarketDataAdnStore 有两个进程在跑？ 关掉一个
```



2.k线程序继续开发

​	createKLine	调试修改一下

​	正式的运行一下

​			打包： mvn clean assembly:assembly

java -jar  datacenter-0.0.1-SNAPSHOT.jar realtime_spif_hbase G:\test\datacenter\config\config.properties



死循环了？		--ok

56261 - 50

while (tickCycle - kCycle > 1)

``` 
kBuff.Timestamp    --不对了？1620316 哪里变的

1620354183700	normtime 》 1620316800

date -d @1620354232

测试一下：
1620354567200
```



看看tick，发送的条数, 数据是否一致		--ok	

 09:30:52 INFO  [store-tick] - store tick: IC05_1620351051

[store-tick] - store tick: IC05_1620358080 ok, 

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1620351051_0", ENDROW => "IC05_1620358080_2"}

本地的：

IC05_1620358080_1                                           column=cf_data:21AskVolume1, timestamp=1620358085233, value=2
12985 row(s) in 48.1530 seconds

线上的：

 IC05_1620358080_1                                           column=cf_data:21AskVolume1, timestamp=1620358081806, value=2
12985 row(s) in 25.6760 seconds

数量			--ok

随便找几条看下数据是否一致		--ok



各个周期的k线

1s:

13:00:02 INFO  [mergeAndstore-kline-1] - store kline IC05_1620363600 to hznc_mkdata:1sdata

13:30:59 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365458 to hznc_mkdata:1sdata ok

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620363600", ENDROW => "IC05_1620365458 "}

本地：

IC05_1620365458                                             column=cf_data:13avgPrice, timestamp=1620365461292, value=6488.0
1788 row(s) in 4.2380 seconds

线上：

 IC05_1620365458                                             column=cf_data:13avgPrice, timestamp=1620365459335, value=6488.0
1788 row(s) in 1.8270 seconds



数量		--ok

数据属性

```
INFO  [mergeAndstore-kline-1] - store kline IC05_1620365490 to hznc_mkdata:1sdata ok
	行 3555: 212093:2021/05/07 13:31:32 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365491 to hznc_mkdata:1sdata ok
	行 3557: 212115:2021/05/07 13:31:33 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365492 to hznc_mkdata:1sdata ok
	行 3558: 212136:2021/05/07 13:31:34 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365493 to hznc_mkdata:1sdata ok
	行 3560: 212169:2021/05/07 13:31:36 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365494 to hznc_mkdata:1sdata ok
	行 3562: 212199:2021/05/07 13:31:36 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365495 to hznc_mkdata:1sdata ok
	行 3564: 212217:2021/05/07 13:31:37 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365496 to hznc_mkdata:1sdata ok
	行 3565: 212234:2021/05/07 13:31:38 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365497 to hznc_mkdata:1sdata ok
	行 3567: 212252:2021/05/07 13:31:39 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365498 to hznc_mkdata:1sdata ok
	行 3568: 212302:2021/05/07 13:31:40 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365499 to hznc_mkdata:1sdata ok
	行 3572: 212318:2021/05/07 13:31:41 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365500 to hznc_mkdata:1sdata ok
	行 3573: 212337:2021/05/07 13:31:42 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365501 to hznc_mkdata:1sdata ok
	行 3575: 212359:2021/05/07 13:31:44 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365502 to hznc_mkdata:1sdata ok

get "hznc_mkdata:1sdata", "IC05_1620365423"				--ok
	09uVolume			private long volume_diff;				//数量差额（当前成交量）
	
	
	
get "hznc_mkdata:1sdata", "IC05_1620365491"				--ok
	12zpos_diff  对应属性 private double openInterest_diff;		//当前持仓量（自己增加）
	cf_data:02dbClosePrice 
	cf_data:03dbHeightPrice                          
	
get "hznc_mkdata:1sdata", "IC05_1620365492"			--ok
	11zpos 应该取最新的
		
get "hznc_mkdata:1sdata", "IC05_1620365494"				--ok
	cf_data:02dbClosePrice                                      timestamp=1620365497354, value=6476.4
 	cf_data:03dbHeightPrice                                     timestamp=1620365497354, value=6476.4
```



5s:

13:00:05 INFO  [mergeAndstore-kline-1] - store kline IC05_1620363600 to hznc_mkdata:5sdata ok

13:34:46 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365680 to hznc_mkdata:5sdata ok



数据量：				--OK

scan "hznc_mkdata:5sdata", {STARTROW => "IC05_1620363600", ENDROW => "IC05_1620365680"}

 IC05_1620365675                                             column=cf_data:13avgPrice, timestamp=1620365680444, value=6488.0
416 row(s) in 0.3000 seconds

数据一致性：

```
 [mergeAndstore-kline-1] - store kline IC05_1620363600 to hznc_mkdata:5sdata ok
	行 17: 165235:2021/05/07 13:00:09 INFO  [mergeAndstore-kline-1] - store kline IC05_1620363605 to hznc_mkdata:5sdata ok
INFO  [mergeAndstore-kline-1] - store kline IC05_1620365585 to hznc_mkdata:5sdata ok
	行 3752: 214872:2021/05/07 13:33:16 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365590 to hznc_mkdata:5sdata ok
	行 3762: 215019:2021/05/07 13:33:20 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365595 to hznc_mkdata:5sdata ok
	 kline IC05_1620365645 to hznc_mkdata:5sdata ok
	行 3864: 216414:2021/05/07 13:34:16 INFO  [mergeAndstore-kline-1] - store kline IC05_1620365650 to hznc_mkdata:5sdata ok
	
	
	get "hznc_mkdata:5sdata", "IC05_1620363600"
	都不对？
```

1min:

数据量：				--ok

[mergeAndstore-kline-2] - store kline IC05_1620363600 to hznc_mkdata:1mindata ok

[mergeAndstore-kline-2] - store kline IC05_1620365520 to hznc_mkdata:1mindata ok

scan "hznc_mkdata:1mindata", {STARTROW => "IC05_1620363600", ENDROW => "IC05_1620365520"}



5min:

store kline IC05_1620363600 to hznc_mkdata:5mindata ok

13:29:59 INFO  [mergeAndstore-kline-2] - store kline IC05_1620365100 to hznc_mkdata:5mindata ok

scan "hznc_mkdata:5mindata", {STARTROW => "IC05_1620363600", ENDROW => "IC05_1620365100"}



性能测试基本ok, 对比了一天tick，各个周期的数据的发送数量基本ok, 

但是部分k线合并价格不对，单元测试调一下

## 20210508

1.每天上班要做的

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	
	两个节点退出了？ keep-0和keep-1
		启动zk节点
		启动regionserver  --ok
		启动datanode      --ok
		
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
	     GetMarketDataAdnStore 有两个进程在跑？ 关掉一个
```

2.继续测试下性能和功能

主力代码是空的？ 查询一下	--今天不开盘

今天没有实时数据，那就用历史数据进行测试。

IC05_1617240600

IC05_1617246059

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1617240600_0", ENDROW => "IC05_1617246059_1"}



5S:

scan "hznc_mkdata:5sdata", {STARTROW => "IC05_1617240600 ", ENDROW => "IC05_1617246050"}

IC05_1617240600  IC05_1617246050  

get "hznc_mkdata:5sdata", "IC05_1617246050"   价格不对			--ok

​	行 2614: 2021/05/08 14:58:07 INFO  [mergeAndstore-kline-1] - store kline IC05_1617240630 to hznc_mkdata:5sdata ok			--ok
​	行 2926: 2021/05/08 14:58:07 INFO  [mergeAndstore-kline-1] - store kline IC05_1617240635 to hznc_mkdata:5sdata ok		--ok

​	e-1] - store kline IC05_1617244575 to hznc_mkdata:5sdata ok																					--ok
​	行 13374: 2021/05/08 14:58:23 INFO  [mergeAndstore-kline-1] - store kline IC05_1617244580 to hznc_mkdata:5sdata ok			--ok

​	store kline IC05_1617246045 to hznc_mkdata:5sdata ok
​	行 15592: 2021/05/08 14:58:28 INFO  [mergeAndstore-kline-1] - store kline IC05_1617246050 to hznc_mkdata:5sdata ok



1min:

store kline IC05_1617240600 to hznc_mkdata:1mindata			--ok

store kline IC05_1617242100 to hznc_mkdata:1mindata ok			--ok

store kline IC05_1617245640 to hznc_mkdata:1mindata ok

line IC05_1617245940 to hznc_mkdata:1mindata ok				--ok

scan "hznc_mkdata:1mindata", {STARTROW => "IC05_1617240600", ENDROW => "IC05_1617245940"}			--OK



30min:

[mergeAndstore-kline-2] - store kline IC05_1617240600 to hznc_mkdata:30mindata ok		--ok
	行 8049: 2021/05/08 14:58:11 INFO  [mergeAndstore-kline-2] - store kline IC05_1617242400 to hznc_mkdata:30mindata ok
	行 8675: 2021/05/08 14:58:13 INFO  [mergeAndstore-kline-2] - store kline IC05_1617244200 to hznc_mkdata:30mindata ok

scan "hznc_mkdata:30mindata", {STARTROW => "IC05_1617240600", ENDROW => "IC05_1617244200"}		

​	



60min:

​	14:58:09 INFO  [mergeAndstore-kline-2] - store kline IC05_1617240600 to hznc_mkdata:60mindata ok
​	行 8677: 2021/05/08 14:58:13 INFO  [mergeAndstore-kline-2] - store kline IC05_1617244200 to hznc_mkdata:60mindata ok

小时k线怎么合并

```
小于0说明是十点半之前的
//十点半之后 十二点之前 
```

d:

scan "hznc_mkdata:ddata", {STARTROW => "IC05_1617240600", ENDROW => "IC05_1619838050"}	



mvn 编译不跑单元测试 -DskipTests

​		数量

​		数据是否正确

​	问题：

​		夜盘是否有

​		合并哪些k线？ 周线和月线？		--ok

​			先合到日线





## 20210510

1.每天上班要做的			--ok

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	
	keep-1:50010
	keep-0:50010
	死掉了？
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
	     GetMarketDataAdnStore 有两个进程在跑？ 关掉一个
```



问题：

102的机器重启后时间变成2015年了		要自动校验一下



2.实时k线继续测试

​		离线的单元测试过

​		本地正式运行起来

​				 mvn clean assembly:assembly

java -jar  datacenter-0.0.1-SNAPSHOT.jar realtime_spif_hbase G:\test\datacenter\config\config.properties

​		检查结果



​		tick:

​		store tick: IC05_1620610420 ok, count: 1

store tick: IC05_1620610869 ok, count: 895

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1620610420_0", ENDROW => "IC05_1620610869_1"}

 IC05_1620610869_0                                           column=cf_data:21AskVolume1, timestamp=1620610868305, value=0
894 row(s) in 5.2700 seconds

IC05_1620610869_0                                           column=cf_data:21AskVolume1, timestamp=1620610869715, value=1
895 row(s) in 1.4970 seconds



bash list_delete_rowkey.sh "hznc_mkdata:tickdata" "IC05_1620610420_0" "IC05_1620610869_1" ic05tick.txt

少了一条？ 启动的时候少了一条		--ok



get "hznc_mkdata:tickdata", "IC05_1620610869_0"

​			1s:

[mergeAndstore-kline-1] - store kline IC05_1620610388 to hznc_mkdata:1sdata ok

IC05_1620610868 to hznc_mkdata:1sdata ok



scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620610388 ", ENDROW => "IC05_1620610868"}			--ok

 IC05_1620610867                                             column=cf_data:13avgPrice, timestamp=1620610868621, value=6437.400000000001
479 row(s) in 0.8960 seconds



store kline IC05_1620610854 to hznc_mkdata:1sdata ok
行 876: 14019:2021/05/10 09:40:52 INFO  [mergeAndstore-kline-1] - store kline IC05_1620610855 to hznc_mkdata:1sdata ok



store kline IC05_1620610865 to hznc_mkdata:1sdata ok
	行 899: 14387:2021/05/10 09:41:04 INFO  [mergeAndstore-kline-1] - store kline IC05_1620610866 to hznc_mkdata:1sdata ok

get "hznc_mkdata:1sdata", "IC05_1620610865"



​			5s

store kline IC05_1620610425 to hznc_mkdata:5sdata ok

store kline IC05_1620610860 to hznc_mkdata:5sdata ok

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620610425", ENDROW => "IC05_1620610860"}			--ok

get "hznc_mkdata:5sdata", "IC05_1620610860"					--ok

​			1min

[mergeAndstore-kline-2] - store kline IC05_1620610320 to hznc_mkdata:1mindata ok

store kline IC05_1620610800 to hznc_mkdata:1mindata ok



scan "hznc_mkdata:1mindata", {STARTROW => "IC05_1620610320", ENDROW => "IC05_1620610800"}			--ok

get "hznc_mkdata:1mindata", "IC05_1620610800"



测试下结果：

tick:

IC05_1620622800 ok, count: 1

store tick: IC05_1620624919 ok, count: 3859



scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1620622800_0", ENDROW => "IC05_1620624919_1"}		--ok

 IC05_1620624919_0                                           column=cf_data:21AskVolume1, timestamp=1620624914896, value=5
3859 row(s) in 19.2580 seconds

get "hznc_mkdata:tickdata", "IC05_1620624919_0"			--ok



1s:

store kline IC05_1620622800 to hznc_mkdata:1sdata ok

store kline IC05_1620624918 to hznc_mkdata:1sdata ok

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620622800", ENDROW => "IC05_1620624918"}				--ok



测试：2118 row(s) in 7.7890 seconds， 线上： 2045 row(s) in 3.7500 seconds

​	数量不一致？对比一下

bash list_delete_rowkey.sh "hznc_mkdata:1sdata" "IC05_1620622800" "IC05_1620624918" ic05_1s_test_txt

IC05_1620622800    13:00:00

IC05_1620624917    13:35:17

35分钟 + 18s = 2118s



get "hznc_mkdata:1sdata","IC05_1620624910"

```
昨收价不对：07dbYTClosePrice
12zpos_diff
不一致：10uVolume_Sell  

1617243766

1617243760

有多线程的问题？？？

```



## 20210511

1.每天上班要做的			--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	
	keep-1:50010
	keep-0:50010
	死掉了？
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
	     GetMarketDataAdnStore 有两个进程在跑？ 关掉一个
```





2.继续测试k线程序

昨收价不对：			--ok

```
get "hznc_mkdata:1sdata", "IC05_1620697385"
昨收价不对：07dbYTClosePrice				昨收价：6443.8		--ok, 结构体中的preClosePrice 不是昨收价，是上周期收盘价格，用来计算涨幅和震幅。

kBuff.PreClosePrice = kBuff.ClosePrice;

12zpos_diff					周期内相加的	-14   现在的是:536905.0？？难道是没有清空			--ok ， 下个周期开始时kbuff中应该reset
不一致：10uVolume_Sell  				--ok， 应该是原来的计算不对

    1617243766

1617243760
```

本地先运行起来，定时观察

java -jar  datacenter-0.0.1-SNAPSHOT.jar realtime_spif_hbase G:\test\datacenter\config\config.properties

​			刚起来的时候kline线程卡住了？  在这个方法里面：_packKLineDayHour



2021/05/11 13:02:01 INFO  [mergeAndstore-kline-1] - store kline IC12_1620709310 to hznc_mkdata:10sdata ok



测试完整的，一天的数据，主要是测试补数据的功能：_packKLineDayHour

2021/05/11 14:51:36 INFO  [mergeAndstore-kline-1] - store kline IH05_1620715894 to hznc_mkdata:2sdata ok



对比下结果：		--ok



最后1s的价格不对		原来的有问题，没有算15:00的tick数据		--ok





装一个leet code插件

明天工作：



明天部署上线



问题： 开盘前的第一个tick撮合到11:30？



3.处理期货数据

共享目录		share (file://PC201812201007/share)

file://10.10.0.16/share

10.10.0.16

今日工作：

20210511

1. 继续测试实时k线程序， 完善单元测试

2. 历史期权数据处理， 与合约执行价关联

​		--明天继续测试

周期优先序为：tick->1s->2s->3s->5m->10m->5s->15s->30s->1m->15m->30m->1h

品种优先序为：IC->IH->IF

5s:

store kline IC05_1620622800 to hznc_mkdata:5sdata ok      13:00:00

tore kline IC05_1620624910 to hznc_mkdata:5sdata ok        13:35:10

scan "hznc_mkdata:5sdata", {STARTROW => "IC05_1620622800", ENDROW => "IC05_1620624910"}			--ok

预期：422

store kline IC05_1620622800 to hznc_mkdata:5sdata ok

[mergeAndstore-kline-1] - store kline IC05_1620624875 to hznc_mkdata:5sdata ok

hznc_mkdata:5sdata ok



```
get "hznc_mkdata:5sdata", "IC05_1620622800"	
07dbYTClosePrice                                    timestamp=1620622855288, value=6430.2
12zpos_diff

get "hznc_mkdata:5sdata", "IC05_1620622800"	
```

1min:

store kline IC05_1620622800  to hznc_mkdata:1mindata ok  13:00

store kline IC05_1620624840 to hznc_mkdata:1mindata ok           13:34:00



scan "hznc_mkdata:1mindata", {STARTROW => "IC05_1620622800", ENDROW => "IC05_1620624840"}			--ok

33条

5min:

store kline IC05_1620622800 to hznc_mkdata:5mindata ok

store kline IC05_1620624000 to hznc_mkdata:5mindata ok

store kline IC05_1620624600 to hznc_mkdata:5mindata ok

scan "hznc_mkdata:5mindata",  {STARTROW => "IC05_1620622800", ENDROW => "IC05_1620624600"}		--ok



6条

get "hznc_mkdata:5mindata", "IC05_1620622800"

get "hznc_mkdata:5mindata", "IC05_1620624000"



60min



主力：			--ok

tick：

scan "hznc_mkdata:tickdata",  {STARTROW => "IC9999_1620622800_0", ENDROW => "IC9999_1620624910_2"}	

5s:

store kline IC9999_1620622800 to hznc_mkdata:5sdata ok

store kline IC9999_1620624910 to hznc_mkdata:5sdata ok



scan "hznc_mkdata:5sdata",  {STARTROW => "IC9999_1620622800", ENDROW => "IC9999_1620624910"}				--ok

422 row(s) in 0.4910 seconds





下午测试下packingKline

问题：				--ok

昨收价不对：07dbYTClosePrice

不一致：10uVolume_Sell  

## 20210512

1.每天上班要做的

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	
	keep-0:50010
	死掉了？
	2021-05-12 08:55:31,664 WARN  [regionserver/keep-0/127.0.0.1:60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2021-05-12 08:55:34,665 INFO  [regionserver/keep-0/127.0.0.1:60020] regionserver.HRegionServer: reportForDuty to master=master,16000,1616666881192 with port=60020, startcode=1620780239570
2021-05-12 08:55:34,666 WARN  [regionserver/keep-0/127.0.0.1:60020] regionserver.HRegionServer: error telling master we are up

不知道是谁，把/etc/hosts修改错了，导致不能和master通信			--ok

	
2.检查程序运行和发送情况							--ok
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 			--ok
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
```



2.测试下实时k线程序

​		本地先跑起来

​		下午一点的数据？		--ok

java -jar  datacenter-0.0.1-SNAPSHOT.jar realtime_spif_hbase G:\test\datacenter\config\config.properties

get "hznc_mkdata:1sdata", "IC05_1617247800" 



scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1617240600", ENDROW => "IC05_1617260400"}

bash list_delete_rowkey.sh "hznc_mkdata:1sdata" IC05_1617240600 IC05_1617260400 ic05.txt



```
(CKBuff.getUtime(false) > 0 && CKBuff.getUtime(false) < 1617240540)|| (CKBuff.TimeStamp > 0 &&CKBuff.TimeStamp < 1617240540)
(cKData.getUtime(false) > 0 && cKData.getUtime(false) < 1617240540)|| (cKData.TimeStamp > 0 &&cKData.TimeStamp < 1617240540)

应该是一个对象重复使用的问题，每个合并任务都clone一份自己的对象就可以了
```



测试packKline:

endTs:1620802800

kbuff:1617260399



1s数据应该是14400条

2s数据应该是7200条

5s是2880条

1min是240条

5min是48条

30min是8条

1h是4条

1d是1条



合理规划一下线程任务：			--ok

1s:14399

2s:7505

3s:4799

5s:2879



3.升级k线程序		--ok



lc插件装一下



今天工作：

20210512

1.测试实时k线程序，完善测试用例

2.实时k线程程序线上升级		--ok

​		明天检查运行情况和运行结果



## 20210513

1.每天上班要做的				--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 

	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
```



2.检查升级情况：

​			程序是否正常运行			--ok

​			tick是否完整		--ok

scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1620869400_0", ENDROW => "IC05_1620889200_2"}

​			合并k线是否正确， 1s, 5s, 1min, 30min		--ok

​			tick和1s数据是否有延迟？		--ok

​			11：30和15:00 补k线		--ok





scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1620869400", ENDROW => "IC05_1620889200"}

​	多了9:29的数据？get "hznc_mkdata:1sdata", "IC05_1620869340" 不是我程序生成的。			--ok



```

 IC05_1620889199                                             column=cf_data:01cSymbol, timestamp=1620889213787, value=IC05
 IC05_1620889199                                             column=cf_data:02dbClosePrice, timestamp=1620889213787, value=6435.0
 IC05_1620889199                                             column=cf_data:03dbHeightPrice, timestamp=1620889213787, value=6438.0
 IC05_1620889199                                             column=cf_data:04dbLowPrice, timestamp=1620889213787, value=6435.0
 IC05_1620889199                                             column=cf_data:05dbOpenPrice, timestamp=1620889213787, value=6438.0
 IC05_1620889199                                             column=cf_data:06dbSum, timestamp=1620889213787, value=2.188408E7
 IC05_1620889199                                             column=cf_data:07dbYTClosePrice, timestamp=1620889213787, value=6506.6
 IC05_1620889199                                             column=cf_data:08uTime, timestamp=1620889213787, value=1620889199
 IC05_1620889199                                             column=cf_data:09uVolume, timestamp=1620889213787, value=17
 IC05_1620889199                                             column=cf_data:10uVolume_Sell, timestamp=1620889213787, value=52139
 IC05_1620889199                                             column=cf_data:11zpos, timestamp=1620889213787, value=65360.0
 IC05_1620889199                                             column=cf_data:12zpos_diff, timestamp=1620889213787, value=5.0
 IC05_1620889199                                             column=cf_data:13avgPrice, timestamp=1620889213787, value=6447.400000000001

```

​		是不是有老的程序在跑， 老的程序过滤掉股指数据： GetMarketDataAndStore_20210513.jar		

1620873259 IH2105

IH05_1620873259_0

​	程序卡住了？

at org.apache.hadoop.hbase.client.HTable.put(HTable.java:542)



补一下tick数据， 检查：

get "hznc_mkdata:tickdata", "IH05_1620873259_0"



删除数据：



ih:

 scan "hznc_mkdata:tickdata", {STARTROW => "IH05_1620867600_0", ENDROW => "IH05_1620891000_2"}

13596 IH 2105 1 Tick Bar.txt		--ok



ic:

16212

if:

21069





今天工作：

20210513

​	1.实时k线程序线上联调，修改收盘补k线的问题	--ok

​	2.补数据		--ok

################

## 20210514

1.每天上班要做的				--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer

	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```



2.实时k线程序升级

​		检查下是否正常运行

​					增加了一个标记：dataSource: dc

scan "hznc_mkdata:tickdata",{STARTROW => "IC05_1620954000_0", ENDROW => "IC05_1620977400_2"}

​		测试数据都放开的情况， 性能测试

​		商品期货的数据什么时候来？ 合并规则？开盘收盘时间？

​			9:00-15:00

```
hbase admin 是否线程安全
getTable.put()

是否可以优化，hbase 批量保存
public void loadTableCache() throws IOException {
    tables = Maps.newConcurrentMap();
    // 需要设置缓冲区
    tables.put(TABLE_TICK,  connection.getTable(TableName.valueOf(TABLE_TICK)));
    tables.put(TABLE_SECOND_ONE, connection.getTable(TableName.valueOf(TABLE_SECOND_ONE)));
    tables.put(TABLE_SECOND_TWO, connection.getTable(TableName.valueOf(TABLE_SECOND_TWO)));
    tables.put(TABLE_SECOND_THREE, connection.getTable(TableName.valueOf(TABLE_SECOND_THREE)));
    tables.put(TABLE_SECOND_FIVE, connection.getTable(TableName.valueOf(TABLE_SECOND_FIVE)));
    tables.put(TABLE_SECOND_TEN, connection.getTable(TableName.valueOf(TABLE_SECOND_TEN)));
    tables.put(TABLE_SECOND_FIFTEEN, connection.getTable(TableName.valueOf(TABLE_SECOND_FIFTEEN)));
    tables.put(TABLE_SECOND_THIRTY, connection.getTable(TableName.valueOf(TABLE_SECOND_THIRTY)));
    tables.put(TABLE_MINUTE_ONE, connection.getTable(TableName.valueOf(TABLE_MINUTE_ONE)));
    tables.put(TABLE_MINUTE_FIVE, connection.getTable(TableName.valueOf(TABLE_MINUTE_FIVE)));
    tables.put(TABLE_MINUTE_FIFTEEN, connection.getTable(TableName.valueOf(TABLE_MINUTE_FIFTEEN)));
    tables.put(TABLE_MINUTE_THIRTY, connection.getTable(TableName.valueOf(TABLE_MINUTE_THIRTY)));
    tables.put(TABLE_HOUR_ONE, connection.getTable(TableName.valueOf(TABLE_HOUR_ONE)));
    tables.put(TABLE_DAY_ONE, connection.getTable(TableName.valueOf(TABLE_DAY_ONE)));
  }
```

09:29 分的数据, 没有归到 09:30?

1.8.7-p357 :003 > get "hznc_mkdata:tickdata","IC05_1620955740_0"
COLUMN                                                       CELL
 cf_data:01cSymbol                                           timestamp=1620955802908, value=IC05
 cf_data:02dbClosePrice                                      timestamp=1620955802908, value=6448.8
 cf_data:03dbHeightPrice                                     timestamp=1620955802908, value=6448.8
 cf_data:04dbLowPrice                                        timestamp=1620955802908, value=6448.8
 cf_data:05dbOpenPrice                                       timestamp=1620955802908, value=6448.8

开盘价：6448.8



界面查询不到数据了？

​	9090端口连不上了，看看进程：thrift2挂掉了。

​		启动：hbase-daemon.sh start thrift2

​	为什么挂掉？

​		

```

2021-05-14 11:51:48,237 ERROR [pool-2-thread-12739] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Bad version in readMessageBegin
        at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:223)
        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27)
        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
2021年 05月 14日 星期五 13:19:08 CST Starting thrift2 on master
```

scan "hznc_mkdata:1mindata",{STARTROW => "IC05_1620954000", ENDROW => "IC05_1620977400"}



商品期货缺数据？		--ok

11:15 - 14:27

今天工作：

2021-05-14

1.股指实时k线程序线上测试

2.hbase 服务故障处理

## 20210517

1.每天上班要做的				--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址： # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```



2.商品数据实时k线程序
		卡死的问题，修复更新			--ok

​		夜盘, 用夜盘的商品数据测试

​				开盘时间由9：:30变为9：00

​	不同合约有不同的交易时间， （实际根据交易所不同来的）：

```
"trade_time_code":[[TS,TF,T,IF,IH,IC]
,[bb,fb,jd,lh,RI,LR,AP,WH,PM,RS,JR,SF,SM,CJ,UR,wr]
,[b,p,y,l,v,a,c,cs,pp,i,m,j,jm,rr,eb,eg,pg,CY,OI,SR,FG,TA,RM,ZC,CF,MA,SA,PF,rb,hc,bu,ru,sp,fu,lu,nr]
,[al,pb,sn,zn,cu,ni,ss,bc]
,[au,ag,sc]]

	// 股指期货区间起始时间和结束时间
	m_begin_times[0].push_back(standard_to_stamp_today("09:30:00"));
	m_begin_times[0].push_back(standard_to_stamp_today("13:00:00"));

	m_end_times[0].push_back(standard_to_stamp_today("11:30:00"));
	m_end_times[0].push_back(standard_to_stamp_today("15:00:00"));

	// 商品期货区间起始时间和结束时间
	m_begin_times[1].push_back(standard_to_stamp_today("09:00:00"));
	m_begin_times[1].push_back(standard_to_stamp_today("10:30:00"));
	m_begin_times[1].push_back(standard_to_stamp_today("13:30:00"));

	m_end_times[1].push_back(standard_to_stamp_today("10:15:00"));
	m_end_times[1].push_back(standard_to_stamp_today("11:30:00"));
	m_end_times[1].push_back(standard_to_stamp_today("15:00:00"));

	m_begin_times[2].push_back(standard_to_stamp_today("09:00:00"));
	m_begin_times[2].push_back(standard_to_stamp_today("10:30:00"));
	m_begin_times[2].push_back(standard_to_stamp_today("13:30:00"));
	m_begin_times[2].push_back(standard_to_stamp_today("21:00:00"));

	m_end_times[2].push_back(standard_to_stamp_today("10:15:00"));
	m_end_times[2].push_back(standard_to_stamp_today("11:30:00"));
	m_end_times[2].push_back(standard_to_stamp_today("15:00:00"));
	m_end_times[2].push_back(standard_to_stamp_today("23:00:00"));

	m_begin_times[3].push_back(standard_to_stamp_today("09:00:00"));
	m_begin_times[3].push_back(standard_to_stamp_today("10:30:00"));
	m_begin_times[3].push_back(standard_to_stamp_today("13:30:00"));
	m_begin_times[3].push_back(standard_to_stamp_today("21:00:00"));

	m_end_times[3].push_back(standard_to_stamp_today("10:15:00"));
	m_end_times[3].push_back(standard_to_stamp_today("11:30:00"));
	m_end_times[3].push_back(standard_to_stamp_today("15:00:00"));
	m_end_times[3].push_back(standard_to_stamp_today("01:00:00"));

	m_begin_times[4].push_back(standard_to_stamp_today("09:00:00"));
	m_begin_times[4].push_back(standard_to_stamp_today("10:30:00"));
	m_begin_times[4].push_back(standard_to_stamp_today("13:30:00"));
	m_begin_times[4].push_back(standard_to_stamp_today("21:00:00"));

	m_end_times[4].push_back(standard_to_stamp_today("10:15:00"));
	m_end_times[4].push_back(standard_to_stamp_today("11:30:00"));
	m_end_times[4].push_back(standard_to_stamp_today("15:00:00"));
	m_end_times[4].push_back(standard_to_stamp_today("02:30:00"));
	
```

维护一个映射表



​		大数据延迟的问题， 增加缓存

```
日志有报错？
2021-05-17 13:15:01 INFO  [mergeAndstore-kline-0] - store kline IH05_1621228495 to hznc_mkdata:5sdata ok
2021-05-17 13:15:01 ERROR [mergeAndstore-kline-1] - org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family table does not exist in region hbase:meta,,1.1588230740 in table 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', CACHE_DATA_IN_L1 => 'true', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'}
	at org.apache.hadoop.hbase.regionserver.HRegion.checkFamily(HRegion.java:7972)
	at org.apache.hadoop.hbase.regionserver.HRegion.get(HRegion.java:6994)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.get(RSRpcServices.java:2110)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34946)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)
```



## 20210518

1.每天上班要做的				--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址： # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```



2.商品实时k线

​	每种合约有不同的交易时间			--ok

​	static变量, 多线程会有问题		--ok

​	休市15分钟，导致30分钟以上周期有错位，测试下			--ok

​		AU02

scan "hznc_mkdata:1sdata", {STARTROW => "au2202_1618531200", ENDROW => "au2202_1618556400"} 

打印出来看看：

bash list_delete_rowkey.sh "hznc_mkdata:1sdata" "au2202_1618531200" "au2202_1618556400" au2202_1s.txt

scan "hznc_mkdata:1sdata", {STARTROW => "au2202_1618531200", ENDROW => "au2202_1618556400"} 

​	夜盘

​		问题：

​		nextBeginTime = nextDayBegin + param->duration[1].begin;

```
是否要区分日盘跟夜盘
private void loadToMap(JSONArray tradeCodeArry, TDurationStruct[] tDurations, Map<String, TDurationStruct[]> map) {
    // 还要区分出日盘跟夜盘的区间
    List<TDurationStruct> nightDuratons = Lists.newArrayList();
    List<TDurationStruct> dayDuratons = Lists.newArrayList();
    for(TDurationStruct duration : tDurations){
      if(duration.begin >= KPARAM_TIME_T2100 && duration.end <= KPARAM_TIME_T0300){
        // 夜盘时间
        nightDuratons.add(duration);
      }else{
        dayDuratons.add(duration);
      }
    }

    int night = 1, day = 0;
    for(int i=0;i<tradeCodeArry.size();i++){
      String tradeCode = tradeCodeArry.getString(i);

      // 还要区分出日盘和夜盘的区间
      map.put(tradeCode+"_"+night, nightDuratons.toArray(new TDurationStruct[nightDuratons.size()]));
      map.put(tradeCode+"_"+day, dayDuratons.toArray(new TDurationStruct[dayDuratons.size()]));
    }
  }
```



pack: 1618549207



    int beginOffset = 0;
    if (param->isNight)
        beginOffset = _60min * 4;


​	大数据延迟的问题

​	

今日工作：

20210518

继续开发商品实时k线的程序，测试夜盘情况

## 20210519

1.每天上班要做的					--ok

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```



2. 商品实时k线升级

	夜盘和日周期k线测试		2h
		对比下是不是代码改错了？  getKNightDay改错了	--ok
			小时的k线好像不对，少了？		--ok,走到日线函数里去了
		运行时间应该是一整天的， 从晚上八点-次日16：00    休眠时间16:00 - 20:00		--ok
		au2202 合约代码转换？
	大数据延迟的问题		1h
		秒级别的都用缓存， 
		一个put多大？ 用 ObjectSizeCalculator.getObjectSize()计算
			puts * 1000: 2696296, 平均：2700 byte
			CKdata: 760 byte
		增加程序运行内存		--ok, 测试只能1G, 线上4G-8G
		找不到code: eb,PK 加一下
	参考	期货交易时间：
	http://www.qhsxf.com/%E6%9C%9F%E8%B4%A7%E4%BA%A4%E6%98%93%E6%97%B6%E9%97%B4.html
	
	是否过滤ic, ih, if		--ok
	丢数据了？IF05_1621387800		--ok 有的
	get "hznc_mkdata:tickdata", "IF05_1621387800_0"
	
	测试一天的数据量, 好像还是有延迟？ 测试不发hbase,是否会延迟
	加快mvn 单元测试，可以多线程：
	mvn -T 2 clean install
	
	todo:
	日线生成好像还有些问题
	周线跟月线, 法定节假日
	有时间再整理重构代码	1h
	
	2021/05/19 16:44:40 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x004f1a55] - Session: 0x1798283b8a70035 closed
	2021/05/19 16:44:40 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x004f1a55-EventThread] - EventThread shut down for session: 0x1798283b8a70035



明天再测试下性能， 数据正确性

​	

```
今天工作：

20210519

继续开发商品实时k线程序，功能基本完成。

​	明天主要再测下性能
```



代码格式化看看		--ok

mvn fmt:format

## 20210520

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```

2.实时k线升级
	测试大数据延迟的问题
		本地测试两个程序，一个发hbase,一个不发，看看主要是不是发hbase慢
		如果还是来不及怎么办？， 考虑将hbase存储改成异步的

​		分钟以上的周期还不能用批量保存？ 延迟会很高

scan "hznc_mkdata:1sdata", {STARTROW => "au02_1621468800", ENDROW => "au02_1621495800"}

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1621468800", ENDROW => "IC05_1621495800"}

1621468800



好像window对进程做了限制，单个进程不能超过多少内存。		

​	bcdedit /set increaseuserva 4096，4096就是4096MB		--没用

​		就设置为1g吧，看是否够用		--ok

​	设置定时任务，每天晚上八点启动，周五，周六，周天不启动

问题：

​		周五，周六，周天程序不停

​		主力代码更新

	回话超时？
		
		2021-05-20 09:00:07 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5] - Initiating client connection, connectString=192.168.198.101:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zoo
	keeper.ReadOnlyZKClient$$Lambda$6/15506156@19afb8e
	2021-05-20 09:00:07 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5-SendThread(192.168.198.1
	01:2181)] - Opening socket connection to server 192.168.198.101/192.168.198.101:2181. Will not attem
	pt to authenticate using SASL (unknown error)
	2021-05-20 09:00:07 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5-SendThread(192.168.198.1
	01:2181)] - Socket connection established to 192.168.198.101/192.168.198.101:2181, initiating sessio
	n
	2021-05-20 09:00:07 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5-SendThread(192.168.198.1
	01:2181)] - Session establishment complete on server 192.168.198.101/192.168.198.101:2181, sessionid
	 = 0x179873a6750001a, negotiated timeout = 40000
	2021-05-20 09:01:08 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5] - Session: 0x179873a675
	0001a closed
	2021-05-20 09:01:08 INFO  [ReadOnlyZKClient-192.168.198.101:2181@0x00a1a8d5-EventThread] - EventThre
	ad shut down for session: 0x179873a6750001a
	
	waiting for 10000 actions to finish on table


今天工作：

20210520

1.修改和测试期货实时k线程序

2.期货实时k线程序线上升级		--ok

​		明天观察下运行情况



3.lc插件安装		--ok

​		

## 20210521

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	启动：hbase-daemon.sh start thrift2
```



问题：

au06		tick数据有问题？

get "hznc_mkdata:tickdata", "au06_1621558879_0"

get "hznc_mkdata:tickdata", "au06_1621558879_1"

scan "hznc_mkdata:1sdata", {STARTROW => "au06_1621558879", ENDROW => "au06_1621566000"}

{STARTROW => "au06_1621558879", ENDROW => "au06_1621566000"}

1621566000



日志太多了	--ok



主连代码没有生成，每天九点更新下			--ok



ic06 7点钟的过滤掉， 先手动删除掉？ 20210521 7:05:17			--ok

ic if ih

scan "hznc_mkdata:tickdata", {STARTROW => "IC06_1621526400_0", ENDROW => "IC06_1621558800_1"}



```
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:a03_1621608114_0
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:b07_1621608114_0
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:c09_1621608114_0
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:c11_1621608114_1
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:c01_1621608114_1
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:cs11_1621608114_1
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:eb12_1621608114_1
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:eb11_1621608114_1
2021-05-20 22:41:55 INFO  [store-tick] - filter tick, closed:eb10_1621608114_1

2021-05-21 07:18:26 INFO  [store-tick] - filter tick, closed:sc08_1621521820_2
2021-05-21 07:18:26 INFO  [store-tick] - filter tick, closed:sc09_1621521820_-1		--ok
```



java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@ea1adb rejected from       --ok  java.util.concurrent.ThreadPoolExecutor@15c7ebe[Running, pool size = 10, active threads = 10, queued tasks = 0, completed tasks = 42583]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(Unknown Source)



测试一下周五到下周一的数据， 跨周的		--ok

Expected :33300
Actual   :26675



3.5夜盘跟3.8日盘

scan "hznc_mkdata:1sdata", {STARTROW => "ag04_1614776400", ENDROW => "ag04_1615186800"}

bash list_delete_rowkey.sh "hznc_mkdata:1sdata" "ag04_1614776400" "ag04_1615186800" ag04_1s.txt

20210305 23:59:59
20210308 09:00:00

缺少： 如果第二天是周末或者节假日不需要补		--ok

20210305 21:28:59

20210305 21:28:54

20210305 21:28:51

20210305 21:28:52   1614950932

从20210305 21:28:52 开始调试：

1614950930



scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1621558800", ENDROW => "IC05_1621580400"}

昨天的：

scan "hznc_mkdata:1sdata", {STARTROW => "IC05_1621645200", ENDROW => "IC05_1621666800"}



工作计划：

本周工作：

​	1.股指实时k线程序开发：

​				整合商品和股指数据处理

​				夜盘数据的测试

​				大数据量的延迟测试



下周计划：

​	股指期货历史数据补录

总结：

​		本周程序主要几个优化：

​			1.交易时间丰富多变，期货数据有包括夜盘的五种交易时间，根据每种合约代码获取对应的交易时间，进行过滤和休盘后的补k操作

​			2.支持夜盘数据

​			3.大数据延迟测试，原来程序存在延迟问题，通过多线程和加缓存的方式暂时解决了延迟问题，但后面如果有更多的数据介入，要考虑多机多进程实现。

​			4.定时的查询更新主力代码



本周工作：

​	实时k线程序开发和上级：支持商品期货的实时处理

下周工作：

​		历史股指期货数据补录



##########################

## 20210524

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi		9:20
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50 @ 废弃，不用了
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2
```



2.升级一k线程序

​			上午观察半天		--ok

​			数据量

​				scan "hznc_mkdata:tickdata", {STARTROW => "IC05_1621818000_0", ENDROW => "IC05_1621841400_3"}

​			夜盘

​			主连数据没有更新？

​			rejectException, 达到最大的线程数量了		--ok

​					提高线程池数量，max: 24

​					拒绝策略，等一下

​					workQueue,换成blockingQueue

3.历史数据补录

​		code 是否要保留21， 22的长度，如果要，实时已经入的是否需要修正

​		历史数据删除?

​		主连数据？

​		是否需要备份， 觉得没有必要：

​			1.先在本地测试，发一年的数据

​			2.线上环境，先补一个月的数据，一个月一个月的进行补录

​			3.补录周期， tick, 1s, 2s... 到天的周期



合约名称修改的问题：

​	1.怎么做兼容， 简称和全称，确定后补录数据也要按照规则

​			rowkey?  是否要变？

4.git仓库

​	笔记

​	脑图



5.后面阶段的计划：

股指历史数据补录 》 商品历史数据补录》期权的历史数据补录

考虑写个服务对外提供hbase的查询服务。

​		今日工作：

​				20210525

​				1.实时k线程序夜盘退出的问题修复

​				2.历史数据补录程序开发



## 20210525

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50 @废弃，不用了
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--重启一下
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：

2021-04-26 09:05:04,005 INFO  [main] http.HttpServer: HttpServer.start() threw a non Bind IOException
java.net.BindException: Port in use: 0.0.0.0:9095
        at org.apache.hadoop.hbase.http.HttpServer.openListeners(HttpServer.java:1017)
        at org.apache.hadoop.hbase.http.HttpServer.start(HttpServer.java:953)
        at org.apache.hadoop.hbase.http.InfoServer.start(InfoServer.java:91)
        at org.apache.hadoop.hbase.thrift2.ThriftServer.main(ThriftServer.java:512)
Caused by: java.net.BindException: 地址已在使用


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控
```



scan "hznc_mkdata:1sdata", {STARTROW => "rb06_1621904400", ENDROW => "rb06_1621906200"}， 没有生成5分钟k线			--ok

​		看看日志， mergeAndStore 线程卡了？ 没有输出。发现有脏数据进来，七点钟进来一些时间戳是十点的数据，应该屏蔽掉的。

​		

wgcloud



大量的timewait?

​		netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' 

buff/cache占用太多

​		做一个检查，大数据运维监控平台？

​					Grafana + prom



2.合约全名称修改兼容的问题

​			rowkey过滤器扫描，行不行

​			数据保存两份？

​		要改哪些程序？

​			其他应该不需要修改，只有实时k线程序。

data_center_run.bat  启动两个进程

​	升级		--ok

​			

```
102上的程序：
定时任务名：GupiaoDayData   
运行程序：D:\TimeTask\mergeEveryday\RunMED.bat    
实现功能：每天收盘后从MySql中读取股票日线数据导入Hbase
			hznc_data:weekdata


定时任务名：RunToSqlServerAndZhuLian			也要升级
运行程序：D:\TimeTask\Zhang\ToSqlServerAndZhuLian.bat
实现功能：每天晚上19:10运行，从hbase读取当天主力合约同步至SqlServer数据库中
104程序：

定时任务名：RunSettlementPrice
	运行程序：G:\TimeTask\SqlServer\RunSettlementPrice.bat
	实现功能：每天执行   从hbase中读取主力合约Tick数据计算结算价并存入sql server数据库中的程序

```



3.股指历史数据补录		--先暂停， 优先处理上面的问题

code 是否要保留21， 22的长度，如果要，实时已经入的是否需要修正

​		历史数据删除?

​		主连数据？

​		是否需要备份， 觉得没有必要：

​			1.先在本地测试，发一年的数据

​			2.线上环境，先补一个月的数据，一个月一个月的进行补录

​			3.补录周期， tick, 1s, 2s... 到天的周期

同步程序也需要修改。。。



scan "hznc_mkdata:1sdata", {STARTROW => "IC06_1621918800", ENDROW => "IC06_1621920000"}

数据丢失？

2021-05-25 13:00:15 INFO  [mergeAndstore-kline-2] - #1, waiting for 1000  actions to finish on table: hznc_mkdata:1sdata

​			性能问题还是什么？



todo:

定时任务名：RunToSqlServerAndZhuLian			也要升级			--ok
运行程序：D:\TimeTask\Zhang\ToSqlServerAndZhuLian.bat
实现功能：每天晚上19:10运行，从hbase读取当天主力合约同步至SqlServer数据库中
104程序：

定时任务名：RunSettlementPrice		--ok
	运行程序：G:\TimeTask\SqlServer\RunSettlementPrice.bat
	实现功能：每天执行   从hbase中读取主力合约Tick数据计算结算价并存入sql server数据库中的程序



今天工作：

​	20210525

​		1.合约名全称化的兼容程序开发和线上升级		--ok





## 20210526

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50 @废弃，不用了
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--重启一下
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控
```



2.合约全称化修改

​		检查下数据量，数据

```
			scan "hznc_mkdata:1sdata", {STARTROW => "au02_1621944000", ENDROW => "au02_1621967400"}
			scan "hznc_mkdata:1sdata", {STARTROW => "au2202_1621944000", ENDROW => "au2202_1621967400"}
```



​	问题：

​		日志分开打

​		还是没有过滤，重启一下程序		--ok, 考虑程序是否做一下控制，收盘时间的数据不要：3:00-8:00，16:00 - 20:00		--ok

​		k线丢了？ 用历史数据测试一下		--ok

​				FG的夜盘，23点的没有补录



历史数据的时间有问题：	

```
FG106,20210407,22:59:59.0,2153.000000,2152.000000,2,2153.000000,69,1435,3088120.000000,9839.000000,2288.000000,2028.000000,2149.000000,2158.000000,2158.000000,9826.000000,
FG106,20210408,22:59:59.0,2153.000000,2152.000000,2,2153.000000,69,1435,3088120.000000,9839.000000,2288.000000,2028.000000,2149.000000,2158.000000,2158.000000,9826.000000,2152.000000
FG106,20210408,22:59:59.0,2153.000000,2152.000000,2,2153.000000,69,1435,3088120.000000,9839.000000,2288.000000,2028.000000,2149.000000,2158.000000,2158.000000,9826.000000,2152.000000
到十点突然更新日期了，导致时间变化不准。
```

21:00 - 23:00   7200

最后tick:FG106_1621954798_1, 22:59:58

最后的1sk: 1621954797,   22:59:57		

好像是没有补最后的k线，看看日志确定下	--没有补k线

​	checkRestPoint方法有问题，23:00 对应-3600



补录下昨天的tick数据		--ok



3.算法，flink

​	String, StringBuffer, StringBuilder

​	LinkedHashMap

​	LinkedHashTreeMap

今日工作：

​	20210526

​	1.修复实时k线线程阻塞的问题

​	2.检查合约全称化程序，暂时运行没有问题



##########################

## 20210527

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50 @废弃，不用了
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--重启一下
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

检查下昨天修复的bug,23点没有补数据
			scan "hznc_mkdata:1sdata", {STARTROW => "au02_1622030400", ENDROW => "au02_1622053800"}
			scan "hznc_mkdata:1sdata", {STARTROW => "au2202_1622030400", ENDROW => "au2202_1622053800"}
			
			scan "hznc_mkdata:1sdata", {STARTROW => "FG06_1622030400", ENDROW => "FG06_1622053800"}
			scan "hznc_mkdata:1sdata", {STARTROW => "FG106_1622030400", ENDROW => "FG106_1622053800"}
			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
thrift 又查询不到数据了？
2021-05-27 08:42:04,032 ERROR [hconnection-0x1b6e8480-metaLookup-shared--pool32-t38] zookeeper.ZooKeeperWatcher: hconnection-0x1b6e8480-0x2794ac470c90056, quorum=master:2181,slave1:2181,slave2:2181,keep-0:2181,keep-1:2181,slave3:2181,slave4:2181, baseZNode=/hbase Received unexpected KeeperException, re-throwing exception
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/meta-region-server

2021-05-27 08:42:04,232 WARN  [hconnection-0x1b6e8480-metaLookup-shared--pool32-t38] zookeeper.ZKUtil: hconnection-0x1b6e8480-0x2794ac470c90056, quorum=master:2181,slave1:2181,slave2:2181,keep-0:2181,keep-1:2181,slave3:2181,slave4:2181, baseZNode=/hbase Unable to get data of znode /hbase/meta-region-server
org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /hbase/meta-region-server
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:127)
        

要加内存了？		--ok,申请了


实时k线程序日志告警：
2021-05-27 08:29:23 INFO  [pool-1-thread-6] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=1000ops, last exception=org.apache.hadoop.hbase.RegionTooBusyException: org.apache.hadoop.hbase.RegionTooBusyException: Above memstore limit, regionName=hznc_mkdata:2sdata,CF,1610786264265.65dbcc8844cccb33431430875bcdaeef., server=slave1,60020,1619400429436, memstoreSize=273584000, blockingMemStoreSize=268435456
	at org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:3784)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2967)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2918)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:823)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:785)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2239)
	at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34958)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)
 on slave1,60020,1619400429436, tracking started null, retrying after=2012ms, operationsToReplay=1000
2021-05-27 08:29:25 INFO  [store-tick] - no tick data.
```





1.定时任务，每天重启thrift

​		找到thrift服务的进程id

jps | grep ThriftServer |awk '{print $1}'

​		杀掉，并且确认

kill 

​		重启并且确认

hbase-daemon.sh start thrift2



配一个定时脚本：

配置定时任务

cp restart_thrift2_server.cron /etc/cron.d/

crontab /etc/cron.d/restart_thrift2_server.cron

确认定时任务：

crontab -l



2.继续开发股指历史数据补录	



3.slave2上线		--ok

```
[hznc_gzdata:ticktest,IC09_1591841969_0,1606300695860.9affdc2e3c0d5b2ebb5f0401ca6c8db4.](http://slave2:60030/region.jsp?name=9affdc2e3c0d5b2ebb5f0401ca6c8db4)
```

清一下僵尸进程：

hbase-daemon.sh start regionserver



slave2,60021,1601288037038-splitting

hadoop fs -rmr /hbase/WALs/slave2,60021,1607766488334-splitting

hadoop fs -rmr /hbase/WALs/slave2,60021,1604044287532-splitting

hadoop fs -rm /hbase/WALs/slave2,60021,1601288037038-splitting

重启一下master, 因为有备份的master,所以没有影响		--ok

晚上观察一下



4.主力合约没有生成的问题		--ok， 明天观察下有没有生成主力数据

​		补录		--ok



5.要加内存了， 写一个报告申请			--ok



6. tick改成毫秒		--这个后面再考虑

今日工作：

20210527

1.写定时脚本，每天凌晨三点重启thrift服务，保证稳定性		--ok

2.股指主连数据补录		--ok

3.继续开发历史数据补录程序



##########################

## 20210528

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：GetMarketDataAndStore		8:50 @废弃，不用了
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--重启一下
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
```



2.继续股指历史数据的补录

​	1.先用历史数据生成k线

​			先补一天，再补一个月》 一年

​	2.输出日k

​	3.写一个删除的程序



本周工作：

1.股指历史数据补录程序开发， 本地测试

2.合约全称化程序修改，上线

3.期货实时k线程序的一些bug修复

下周工作：

1.股指历史数据线上补录



3.tcp6连接很多？cpu型号



4.slave2节点看看

ip没有改变？

应该是：10.10.0.54  slave2

​	slave2/10.10.0.15:60020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: slave2/10.10.0.15:60020 on slave2,60020,1622105907095, tracking started null, retrying after=10074ms, operationsToReplay=651



5.生成日线程序有问题？

​			中间升级，使用batch插入，没有配hznc_mkdata:ddata的缓存，导致没有插入进去		--ok,已更新





##########################

## 20210531

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			7.92 TB (16.9%)
			36.1 TB (77.05%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
```



商品夜盘数据不正常， 只到05.29 00:17, realtimedatasource 停了？没有推送数据，也加一下日志。		--ok



​	看下tick数据：

1. 28夜盘数据，截止到0点17分就没有了

​		scan "hznc_mkdata:tickdata", {STARTROW => "au06_1622217600_0", ENDROW => "au06_1622226600_2"}	

2.推送过来31号的数据？

​	scan "hznc_mkdata:tickdata", {STARTROW => "eb08_1622206800_0", ENDROW => "eb08_1622473199_2"}



​		初步判断是因为大商所的字段跟其他交易所字段不一致导致，其他交易所自然日字段为28号，而大商所的自然日为31号。



rb09 没有1分钟k线， 5-28 22:43

scan "hznc_mkdata:tickdata", {STARTROW => "rb09_1622379600_0", ENDROW => "rb09_1622399400_2"}



前十分钟数据丢了？补一下		--ok

scan "hznc_mkdata:tickdata", {STARTROW => "au06_1622422800_0", ENDROW => "au06_1622423460_2"}

跑一下25,26,27

2.股指历史数据修正

​		1.本地发送测试

​		2.删除旧数据

​				历史旧数据：

​					date -d @1604970000
​					2020年 11月 10日 星期二 09:00:00 CST

​					时间戳设为历史的

​					可以稳定的发送

​					合并的k线是对的

​		3.生成日k数据，获取主力代码



今天工作：

20210531

1.股指历史数据补录，本地测试



todo:

新的项目架构：

​	kafka + redis + flink + hbase

学习：

​	hive + spark + hadoop

源码：

​	kafka, hbase

SPI ,serviceLoader

hbase性能测试，吞吐量如何？

用flink去实现k线合并的程序

装一套hive,跟hbase集成

装一套监控的系统

看看：

开仓，平仓

盘面资金

大单数据

北向资金

策略

主力合约Tick数据

股指

期权

股票的开盘时间

主连

股票



代码问题：

​	日志问题，直接System.println.out

​	配置文件，ip端口直接写死的

​	打出来的jar包是用eclipse导出来的，应该用mvn install

​	依赖的jar包直接提交了

​	代码格式化问题，格式太乱，大量重复代码，没有用到的变量。

​	单元测试



## TODO



LinkedBlockingQueue 线程安全

算法和计算机原理

flink

clickhouse

mysql

数据仓库








​	