## tips

释放buffer/cache的内存：

```
释放缓存区内存的方法
sync# 将内存中数据同步到磁盘

 a）清理pagecache（页面缓存）

# echo 1 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1

　 b）清理dentries（目录缓存）和inodes
# echo 2 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2
　 c）清理pagecache、dentries和inodes

# echo 3 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3

# 如何限制buffer/cache的占用？
```

注意：

夜盘数据比较特殊,  比如 2021-04-01 21:00:00 ~ 2021-04-02 00:00:00 的数据, 其实是 2021-03-31 21:00:00 ~ 2021-04-01 00:00:00 的数据.  即夜盘一整天的开盘时间是 昨天 21:00

maven 官方下载地址：

https://archive.apache.org/dist/maven/maven-3/

服务器地址：

```
10.10.10.104   administrator  Admin123
10.10.10.102 administrator  Admin711406
```



个人开发的软件源代码需要每月备份到网络硬盘(在资源管理器输入\\10.10.10.3进入),用户名:各人中文姓名,密码:89024521



这个SVN地址是你的私人地址，你可以提交任何临时代码。
：https://10.10.10.102/svn/private_source/wangtao
账户名和密码是名字全拼。

项目 SVN 地址:
https://10.10.10.102/svn/量化系统/nc_tree_parse/nc_algo

confluence 地址：http://10.10.0.47:8090/

​	ftp:list_delete_rowkey.shb

	   历史股指期权 和 商品期权 数据的下载地址 ：
	   域名：tik-ftp.citicsf.com 端口：8371
	   电信IP：58.33.80.163     端口：8371
	   联通IP：140.206.97.123 端口：8371
	   李佳桧/83g3Mh7m

​	历史数据：

​		50ETF期权数据
​		CFFEX股指期货
​		DCE大连商品
​		CZC3郑州商品
​		SHFE上海商品

钉钉邮箱：wangdao6551@dingtalk.com

能诚账号：u00479密码：1

jira账号：u00479/123456

jira   ip地址更换成：http://10.10.0.47:8080/

svn账号和密码：liuzhenjiang/liuzhenjiang

hbase:
	hadoop-daemon.sh start datanode
	hbase-daemon.sh start regionserver
	tail  -n -500 /usr/local/hbase/logs/hbase-hadoop-regionserver-slave4.log

sql server:

10.10.10.8

​		properties.setProperty("user", "R16");
​		properties.setProperty("password", "R16_0625");

现有集群规模：共有七台机器，老机房两台，新机房五台。

老机房两台：

​     主机名：keep-0        IP：10.10.10.110    nc_007用户登录密码：nc_007

主机名：keep-1        IP：10.10.10.111       nc_008用户登录密码：nc_008

 ![image-20210510085345685](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210510085345685.png)

新机房五台：

​     主机名：master      IP：10.10.0.254        root用户登录密码：1

主机名：slave1        IP：10.10.0.119        root用户登录密码：1

主机名：slave2        IP：10.10.0.54        root用户登录密码：1

主机名：slave3        IP：10.10.0.253        hadoop用户登录密码：1

主机名：slave4        IP：10.10.0.252        hadoop用户登录密码：1

 

集群配置：

​     三台zookeeper，七台HDFS（master，slave1，上运行namenode，七台DataNode）

​     Master，slave3作为HBASE的HMaster节点，除master节点之外，六台起HRegionserver服务，HMaster节点需要另起ThriftServer服务来提供读取数据服务。集群启动步骤见《集群各项服务启动命令.txt》文件

Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas

HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview



git key: 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



## 每天做的

```
1.检查下hadoop集群, hbase集群
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi，
    	  
10.10.10.102 administrator/Admin711406  
	进程：GetMarketDataAndStore
	     GuPiaoReduce（RunDataMerge?）
```



###################

## 20210601

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
	
```



2.继续股指历史数据补录

​	进程oom的问题

 [hconnection-0x1b03244-metaLookup-shared--pool3-t31] - Call exception, tries=10, retries=16, started=47592 ms ago, cancelled=false, msg=Call to vm01/192.168.198.101:16201 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information: vm01/192.168.198.101:16201, details=row 'hznc_mkdata:2sdata,IF1503_1420508812,99999999999999' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=vm01,16201,1622451944197, seqNum=-1, see https://s.apache.org/timeout



​	单元测试改成离线的也能正常运行

​	支持继续发送

hbase 不断自动的split?

因为过大的内存会导致GC时间过长（GC方式从CMS改为G1后可以增大该值，机器内存足够的情况下可以翻倍甚至更大）。 ((RS Xmx) *hbase.regionserver.global.memstore.size) / (hbase.hregion.memstore.flush.size *(# column families))。      *

* 即16G*0.45/128M=64个





补数据：

get "hznc_mkdata:tickdata", "IC06_1622528746_0"



20210601 14:26:00 没有补数据？



一些表设置了TTL？ 整理下

用新的表测试？

create 'hznc_mkdata','cf_data'



create "hznc_mkdata:tickdata_his", {NAME => "cf_data", VERSIONS => 1, COMPRESSION => "snappy", BLOCKCACHE => "TRUE"}

create "hznc_mkdata:ddata_his", {NAME => "cf_data", VERSIONS => 1, COMPRESSION => "snappy", BLOCKCACHE => "TRUE"}



## 20210602

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
	
	toSqlserver程序
```



补数据程序做个版本

​	参考文档《数据修订和核对流程.md》

​	检查各个子进程		--ok

​			todo: datasource, 先用日志观察

  1.修订的程序不要在本地运行了，升级到线上服务器，在线上的服务器进行补录

  2. 代码分支管理：

       	建两个分支，dev分支和master分支。开发在dev分支上，开发完成测试通过合并到master

     ​	master运行稳定一周后，打一个tag， 升级版本。

3.实时k线，包含15:00的？  --好像是客户端的问题？

​	scan "hznc_mkdata:5mindata", {STARTROW => "IF2106_1622595600", ENDROW => "IF2106_1622619000"}



2.继续历史股指补录

​		

3.TTL的问题

​		

4.数据补录的问题

​		1.数据发重复了？		--没有，看错了

​		2.k线合并有问题，价格不对

​		3.数据发不进去？ 时间戳不对还是刷新缓存

```
if (HISTORY_SPIF_HBASE.equals(runMode) && false) {
  put.addColumn(
      family, qualifier, ts, // 历史数据时间戳用历史的，方便删除
      value);
```



​		4.java64 加载不了native库？		--使用32位java

​		5.历年的休假时间

```
数据补录的会议：
1.跟中信确认下生成时间

2.策略部，后面找一下是否可以包含成交量为0的数据

3.昨日收盘价格用程序去读


数据核对：
查询tick的数据跟源文件中对比一致，可以程序去对比

每个合约不同交易时间，k线个数不一样，可以动态的去对比


开发补数据完通知到测试，测试通知到策略部

补录数据反馈要及时

自动化完成之前每日收盘开发跟测试验证数据

后面自动化：
补数据时，客户端可以提示数据异常，正在补录。

王涛：
程序兼容两种格式
补录程序部署到线上
分支标准化
补数据的流程化

吴凯伦：
程序稳定性，测试
导出格式固定

```





今天工作：

20210602

补录程序的问题修改，合并k线测试

补数据流程文档



## 20210603

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```

​	regionServer释放内存？

释放buffer/cache		--ok

如何限制buffer/cache 的占用？

AP220没有9:00跟9:01的k线？1min

scan "hznc_mkdata:1mindata", {STARTROW => "AP2201_1622682000", ENDROW => "AP2201_1622682180"}



查一下早上8点-8点半的

scan 'hznc_mkdata:1sdata', {TIMERANGE => [1622678400000, 1622680800000]}



可能要把8：55之前的数据屏蔽掉		--ok

2021-06-03 08:00:02 INFO  [store-tick] - store tick: FG106_1622732393_0 ok, count: 6725
2021-06-03 08:00:03 INFO  [store-tick] - store tick: au2202_1622658600_1 ok, count: 6726



2.补录程序修改：

​	1.带时间戳发不进去？调试一下		--ok，去掉，不使用时间戳了

​	2.补录程序发布版本更新上线

​			自动查询前一天的收盘价		--ok

​			优化保证稳定不死

​					calendar.setTime(new Date(ts)) -> calendar.setTimeImillis(ts);

​					updateKline 去掉clone方法

​					string[] splits = line.split(",") 改成直接统计了

​			历年的休假时间，节假日时间，从国务院官网爬取的：			--ok

​					https://github.com/NateScarlet/holiday-cn/blob/master

​			jna是否可以固定线程

​		可能要把8：55之前的数据屏蔽掉		--ok

盘后检查数据的程序，k线		--ok

​	3.本地运行		--ok



TTL修改，先找一个表测试		--ok

hznc_mkdata:1sdata：   无

​		'hznc_mkdata:2sdata', {NAME => 'cf_data', TTL => '2592000 SECONDS (30 DAYS)'}

​		'hznc_mkdata:3sdata', {NAME => 'cf_data', TTL => '2592000 SECONDS (30 DAYS)'}

​		hznc_mkdata:5sdata', {NAME => 'cf_data', TTL => '3888000 SECONDS (45 DAYS)'}

​		'hznc_mkdata:10sdata', {NAME => 'cf_data', TTL => '5184000 SECONDS (60 DAYS)'}

​		'hznc_mkdata:15sdata', {NAME => 'cf_data', TTL => '5184000 SECONDS (60 DAYS)'}

​		'hznc_mkdata:30sdata', {NAME => 'cf_data', TTL => '7776000 SECONDS (90 DAYS)'}

​		'hznc_mkdata:1mindata', {NAME => 'cf_data'}		无

​		'hznc_mkdata:5mindata', {NAME => 'cf_data'} 	无

​		'hznc_mkdata:15mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:30mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:60mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:ddata', {NAME => 'cf_data'}	无

hznc_mkdata:tickdata  365天

如果修改也比较简单，但要再盘后修改，因为要先disable掉表：



​	describe "hznc_mkdata:ticidata" # 查看确认下表结构

​	disable 'hznc_mkdata:tickdata' # 先禁用表

​	alter 'hznc_mkdata:tickdata' , {NAME=>'cf_data',TTL=>'2147483647', COMPRESSION => "snappy"}  # 不删除,使用压缩

​	enable 'hznc_mkdata:tickdata'  # 恢复表



disable 'test_xiao' # 先禁用表

​	alter 'test_xiao' , {NAME=>'test_xiao',TTL=>'2147483647', COMPRESSION => "snappy"}  # 不删除,使用压缩

​	enable 'test_xiao'  # 恢复表





今日工作：

20210603

离线补录程序的修改和完善：

​	统计和支持加载历年的节假日日期

​	开发简单的程序自动检查盘后实时数据





###################

## 20210604

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.54 TB (18.22%)
			35.48 TB (75.72%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```



2.继续开发历史数据补录程序

​	日志按照天输出		--ok

​			log4j:WARN No such property [datePattern] in org.apache.log4j.RollingFileAppender. 不支持属性datePattern

​			log4j.appender.main=org.apache.log4j.DailyRollingFileAppender  不支持属性maxFile

​	补录程序稳定不死

​			Exception in thread "main" java.lang.IllegalStateException: Queue full

​			jprofile 调一下

​				最大内存：512M

​		线程卡住了?

​		

``` s
if (tickData.Volume < 0 || tickData.Amount < 0) {
  return;
}
是负的？
```



```
2021/06/04 11:27:06 INFO  [store-tick] - store tick: IF1502_1422845600_0 ok, count: 131203
2021/06/04 11:27:06 INFO  [store-tick] - store tick: IF1502_1422845600_1 ok, count: 131204
```



​	离线数据的单元测试		--ok





###################

## 20210605

1.历史数据补录

​		线程卡死的问题，看看是不是linkedBlockingqueue导致的

​			poll方法？

java.lang.NullPointerException
	at com.hznc.datacenter.task.MergeAndStore.updateKParam(MergeAndStore.java:179)
	at com.hznc.datacenter.task.MergeAndStore.getParam(MergeAndStore.java:165)
	at com.hznc.datacenter.task.MergeAndStore.mergeAndStoreKline(MergeAndStore.java:152)
	at com.hznc.datacenter.task.MergeAndStore.run(MergeAndStore.java:110)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)



线程死掉了，死掉怎么不说？			--ok



发送起来：

8.47 TB (18.08%)，  35.55 TB (75.87%)



```
kCycle  1420394399 应该是：
```

：1420394400 -1



###################

## 20210607

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.57 TB (18.28%)
			35.45 TB (75.66%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```





2.离线数据补录

​		TF这些是否要发？		--ok, 发送

​		部署到线上环境			--ok

​		检查下，日志中的报错，是否可以优化

​			又是这个问题：

		2021/06/07 09:11:50 WARN  [Default-IPC-NioEventLoopGroup-1-8] - A task raised an exception. Task: org.apache.hadoop.hbase.ipc.NettyRpcConnection$6$1@18a34f1
		java.lang.OutOfMemoryError: Java heap space
	
	​					2021/06/07 09:11:50 WARN  [Default-IPC-NioEventLoopGroup-1-6] - Unexpected exception in the selector loop.
	​					java.lang.OutOfMemoryError: Java heap space
	
	​					waiting for 1000  actions to finish on table
	
	表在split时引起的？
	每次写的批量太大引起的？ 计算puts的大小：
		2737776 byte  2.6MB
	默认的pool大小？
	
	    ThreadPoolExecutor tpe = new ThreadPoolExecutor(
	        coreThreads,   // 256, 如果是获取meta表128
	        maxThreads,    // 256, 如果是获取meta表128
	        keepAliveTime, // 60
	        TimeUnit.SECONDS,
	        workQueue, // LinkedBlockingQueue
	        Threads.newDaemonThreadFactory(toString() + nameHint));
	    tpe.allowCoreThreadTimeOut(true);
	    使用默认的，测试一下


​	    
​	    检查实时数据：
​	    ic: 			策略：25891       数据中心：25888	监控中心：25888
​	    ih: 			策略：25087       数据中心：25084	监控中心：25084
​	    if:				策略：27769       数据中心：27766	监控中心：27766


​			

​		实时k线重启一下		--ok

​		补录一下周五的日k		--ok



3.继续安装hive

​	安装mysql



动态规划





今日工作：

20210607

1.历史股指数据补录

​	已经发完2015-2016年的数据

2.盘后补录程序线上部署		--ok



###################

## 20210608

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.68 TB (18.53%)
			35.34 TB (75.42%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```



2.股指历史数据继续发送

​	2015		--ok

​	2016		--ok

​	2017	--ok

​	2018	--ok

​	2019

​	2020

​			IO2002-C-3550 这个合约？先去掉， 后面有需要再发

​	在线上环境运行了，本地太占资源

​	写个删除的程序， 输入合约代码 + 开始时间 + 结束时间

​		1.从文件查找列出所有要删的合约代码， 要删除的表，tick + 日k线

​		2.scan查询要删除的行（没有from:dc属性的）

​		2020-2021.5.12

3. 6.4日，周五的夜盘数据切换到6.7日，周一的夜盘了？		--ok, 时间戳直接使用utime字段，不用交易日取日期

​	日期使用的是这个字段： byte[] TradingDay = new byte[8]; // 交易日    工作日



4.补一下商品数据：			--ok

c2109，jm2109 , j2109 , ZC109 , i2109

6月3号21点到6月7号21点

1622725200 - 1623070800

5.升级程序				--ok

​	晚上观察一下



2021-06-08 14:10:00    1623132600

2021-06-08 14:15:00

hbase 手动维护compaction?



 c2109_1623078000_0                                          column=cf_data:from, timestamp=1622818805177, value=dc
11248 row(s) in 26.0450 seconds



今日工作：

20210608

1.股指历史数据继续发送

​			2017-2018已经发完成

2.修复夜盘数据时间错乱的问题

3.商品数据补录



## 20210609

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.68 TB (18.53%)
			35.34 TB (75.42%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
	
	行情界面查询的数据跟hbase不一致？
	
	大商所的时间有问题			--不用处理了，肖兵那边处理
		判断当前日期跟tick日期
	
	程序卡死的问题？     开会的时候程序卡死了？  好像还是有脏数据推过来
		过滤到8:59

```





1.程序卡死的问题？		--ok

​		开会的时候程序卡死了？  好像还是有脏数据推过来, 过滤掉59分



3.写个程序删除旧数据

​		盘后, 等客户端切换成全称后再删除吧

​		tick数据没有生成？？？ 应该是只有19年的

​				storeTickEnable=false



​		清除6.9 21-23的数据			--ok

​				批次修改成500好像更加稳定？

​		继续补录21年的数据

​				

```
报错：
2021/06/09 15:26:33 INFO  [pool-1-thread-3] - id=1, table=hznc_mkdata:tickdata, attempt=11/16, failureCount=1000ops, last exception=org.apache.hadoop.hbase.RegionTooBusyException: org.apache.hadoop.hbase.RegionTooBusyException: Above memstore limit, regionName=hznc_mkdata:tickdata,IF1903_1537250654_0,1623223472026.b00302f355fec13c4895006572066f10., server=slave3,60020,1619400396937, memstoreSize=269743272, blockingMemStoreSize=268435456
        at org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:3784)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2967)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2918)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:823)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:785)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2239)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34958)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)
 on slave3,60020,1619400396937, tracking started null, retrying after=10081ms, operationsToReplay=1000
```



4.主力切换规则

​	先看看如何生成



5.简单使用hive,创建hive 和hbase的表关联		--ok

​	学习hive常用的语句，哪些会触发mr任务

WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.



今天工作：

20210609

1.股指历史数据补录

​		2015年-2020年的股指数据已补完

2.修复大商所夜盘商品数据时间错乱的问题

3.期货主力合约计算程序 ， 还在设计中



## 20210610

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发



3.程序早上没有重启，开盘有问题？

​		还是要早晚重启？不然不太稳定



4.检查下数据，股指历史数据补录的

​		实时发送，批次改成100看是否有延迟, 还是有1-2分钟的延迟

​		修改成500应该没有问题



今日工作：

20210610

期货主力规则切换算法开发

实时期货数据检查		--ok



5.

String, StringBuffer和StringBuilder

> ```java
> public final class String
>     implements java.io.Serializable, Comparable<String>, CharSequence { // final修饰，表示不可继承
>     /** The value is used for character storage. */
>     private final char value[]; // 存储字符，final修饰，一旦赋值就不能重新引用对象
> 
>     /** Cache the hash code for the string */
>     private int hash; // Default to 0
> 
>     /**
>     String 是一个特殊的类：
>     1.使用“+” 拼接字符串时，jvm在编译时进行优化，如果是字符串常量拼接，编译后直接是拼接后的结果，如：
>     String value = "hello" + "world"; 编译后：String value = "helloworld";
>     如果不是常量拼接，编译后会转换成StringBuilder进行拼接：
>     String value = "count" + i; 编译后：String value = new StringBuilder("count").append(i);
>     
>     2. 如果直接String value = "helloworld";方式创建字符串，编译期间JVM就会到字符串常量池检查是否有字符串对象，没有就创建放到常量池，然后返回。
>     而    String value = new String("helloworld"); 编译期间检查字符串常量池中是否有“helloworld”，没有就创建。运行期间直接在堆中创建对象，然后返回堆中对象的引用。所以可能创建一个对象也可能两个。
>     
>     3.字符串常量池
>     jdk1.8前后有区别， 1.8之前常量池在永久代(permGen),1.8及之后再堆内存中。
>     顺便提一下，1.8之后永久代被元空间替代，跟堆内存在一起。
>     4.intern方法
>         intern方法的注释已经很好的说明了intern方法的执行逻辑：When the intern method is invoked, if the pool already contains a string equal to this object as determined by the equals method, then the string from the pool is returned. Otherwise, this object is added to the pool and a reference to this object is returned。All literal strings and string-valued constant expressions are interned。
>     简单翻译一下就是分以下三个情况：
>     1.执行intern方法时，如果字符串常量池中已经包含执行intern方法的String对象，则直接返回字符串常量池中的String对象；
>     2.执行intern方法时，如果字符串常量池中不包含执行intern方法的String对象，则先将该String对象添加到字符串常量池中，然后将字符串常量池中的String对象返回；
>     3.字符串字面常量（literal strings，如"a"，"b"）和字符串常量表达式（string-valued constant expressions，如"a" + "b"）也都要放到字符串常量池中。
>     随着虚拟机结构的调整，intern执行的结果在情况2下有些差异。Jdk1.6中的字符串常量池是放在永久代（Perm）区中的，永久代（Perm）区和正常的 JAVA堆（Heap ）区域是完全分开的。上面说过literal strings 和 string-valued constant expressions会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap区域。而Jdk1.8取消了永久代（Perm），字符串常量池就从 Perm 区移到正常的Java Heap 区域了。由于上面的调整，导致intern方法执行结果在jdk1.6和1.8下存在差异。
>     }
> 
>     private static void callInternMethodStringPoolNotExist() {
>         String value = String.valueOf('a');
>         String valueIntern = value.intern();
>         System.out.println(value == valueIntern);
>     }
>     Jdk1.8版本下，执行结果打印true。执行过程如下：
>     1.String value = String.valueOf('a')，'a'是primitive type，数据直接存储在栈上。然后再创建一个新的String对象value，value的内容为"a"，执行完常量池中并没有值为"a"的对象；（注意：如果直接String value = new String("c");执行首先检查常量池有没有，没有就创建，然后堆中创建一个对象）
>     2.执行String valueIntern = value.intern()，此时常量池里中还没有字符串"a"对象了，而Jdk1.8字符串常量池就在堆区，可以直接拿到value的引用，放到常量池中，然后返回value的引用，赋值给valueIntern；
>     3.System.out.println(value == valueIntern)，打印true，因为value和valueIntern都指向value的引用。*/
>     
>    
>    
> StringBuilder:
> public final class StringBuilder  extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 因为string是不可变的，所以提供可变的StringBuilder,来操作字符串
> public StringBuilder() { super(16);} // 默认的capacity是16
>     
> public StringBuilder(String str) { super(str.length() + 16);   append(str);} //始终保持16长度的空余 
>     
>  append方法：
>      public AbstractStringBuilder append(String str) {
>         if (str == null)
>             return appendNull();
>         int len = str.length();
>      	// 如果容量不够则创建足够容量的字符数组，然后通过System.arraycopy的方式填充
>         ensureCapacityInternal(count + len); 
>         str.getChars(0, len, value, count);
>         count += len;
>         return this;
>     }
>     
> StringBuffer:
> public final class StringBuffer    extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 跟StringBuilder一样都继承自AbstractStringBuilder类，但对几乎所有方法都进行重新加上了synchronized修饰方法
>         
> ```



​	threadLocal 和ineritableThreadLocal



```java
    public void set(T value) {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null)
            // 当前的threadLocal对象为key,保存到线程的成员变量ThreadLocalMap中去
            map.set(this, value);
        else
            createMap(t, value); // t.threadLocals = new ThreadLocalMap(this, firstValue);
    }   


public T get() {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null) {
            /**
            To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys
            */
            ThreadLocalMap.Entry e = map.getEntry(this); // Entry是一个弱应用
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue(); // 初始化<Thread.currentThread(), null>，然后返回value: null
    }


      private Entry getEntry(ThreadLocal<?> key) {
          // 用当前threadLocal对象的hashcode和table进行取模计算下标
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.get() == key)
                return e;
            else
                return getEntryAfterMiss(key, i, e); // 发生hash碰撞后，并不是以链表形式去保存和取，而是取下标的后一位：nextIndex(i, len)
        }

public class InheritableThreadLocal<T> extends ThreadLocal<T> {}// 子线程可继承的ThreadLocal
    
//  Thread的init方法中：
  this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
// 再看看createInheritedMap：
return new ThreadLocalMap(parentMap);

// 实现可继承ThreadLocalMap的构造方法
  private ThreadLocalMap(ThreadLocalMap parentMap) {
      		// 根据父类ThreadLocalMap初始化子类的Table,就是一个Entry数组
            Entry[] parentTable = parentMap.table;
            int len = parentTable.length;
            setThreshold(len);
            table = new Entry[len];

            for (int j = 0; j < len; j++) {
                Entry e = parentTable[j];
                if (e != null) {
                    @SuppressWarnings("unchecked")
                    ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();
                    if (key != null) {
                        Object value = key.childValue(e.value); // return value; 这个key实际是InheritableThreadLocal, 实现了childValue,而ThreadLocal没有实现的。
                        Entry c = new Entry(key, value);
                        int h = key.threadLocalHashCode & (len - 1);
                        while (table[h] != null)
                            h = nextIndex(h, len);
                        table[h] = c;
                        size++;
                    }
                }
            }
        }

```



LinkedBlockingQueue



## 20210611

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```





2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[T152_151LOG]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_tme] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


```

3.程序早上没有重启，开盘有问题？		-- 继续观察测试

​		还是要早晚重启？不然不太稳定，还是解决稳定性的问题，继续观察



4.检查下数据，股指历史数据补录的		--OK

​		实时发送，批次改成100看是否有延迟, 还是有1-2分钟的延迟

​		修改成500应该没有问题

​		21年的可以发起来



## 20210615

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```





2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

​		保存持仓量，成交量

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[T152_151LOG]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_tme] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


```



今日工作：

20210615

期货主力规则切换算法开发 --明天开始测试

上周夜盘商品数据补录  --ok

实时期货数据检查		--ok



## 20210616

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

​		保存持仓量，成交量

​		6.11夜盘数据不应该有， 节假日放假前那个工作日夜盘不开市的 删掉先

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[futures_main_contract]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[volume] decimal(18, 2) NOT NULL,
	[open_interest] decimal(18, 2) NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_time] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
volume, 
open_interest,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


insert into table dbo.futures_main_contract (contract_code,future_variety,volume, open_interest,start_date,end_date,update_time) values()


新增两个字段：
Volume 成交量
OpenInterest 持仓量

```



thrift2挂了：

bash /usr/local/hbase/bin/restart_thrift2_server.sh



今日工作：

20210616

1.期货主力规则切换程序本地测试和一些逻辑修改



###################

## 20210617

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.73 TB (18.64%)
			35.28 TB (75.29%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？		--ok

​		保存并更新持仓量，成交量		--ok

​		还是从hbase捞出来快一点				--ok

​				filter实现，扫描日k表，按照utim过滤

​		实时的运行起来		--ok

​		历史的先生成， IC, IH, IF		--ok

​			2015-09-03 到2015-09-06都在休息，抗战胜利周年庆，但是节假日里面没有所以导致缺失了2015-09-07的主力合约

​		本地运行起来，测试夜盘数据卡住的问题

todo: 合约品种都改成小写





###################

## 20210618

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.73 TB (18.62%)
			35.29 TB (75.31%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

主力合约生成程序开发

​	验证生成的主力代码		--ok

​			日k线插入到数据库中		--ok

​			使用方法:

​				10.10.10.8服务器上的Index_Data_his数据库

​				1.进入Index_Data_his数据库, 将需计算的数据存入“T003_主力合约待计算表”;
​				2、执行“C001_批量计算期指主力合约”存储过程;
​				3、查看“T004_主力合约代码”表

​	生成股指主连数据

​	

跑夜盘数据程序的问题

​		断点看看什么造成的， pass

```
kCycle = (kBuff.TimeStamp - beginOffset - kBreakOffset) / param.cycle; // kBreakOffset不应该是0，已经休息了一夜了


断点：
        // K 线时间点已经历的小节休息时间
        if ((kMod - beginOffset) % _1day >= begin - beginOffset) {
          restTime = param.durations[i].begin - param.durations[i - 1].end;
          if (restTime < _60min * 3) {
            kBreakOffset += restTime;
          }
        }
```



周末吧数据发送2021-01到2021-06的数据发送起来



###################

## 20210619

hashMap 和hashSet， LinkedHashMap

```java
public class HashMap<K,V> extends AbstractMap<K,V>    implements Map<K,V>, Cloneable, Serializable:
// 几个重要的成员变量
/**
   * The default initial capacity - MUST be a power of two.
   * 默认的容量，必须是2的次方：
   * 为了保证每个桶内的元素尽可能均匀的， 对添加的元素进行取模得到下标：h & (length-1)
   * 如果length不是2的次方如：10，假如现在有hash值为11和9，那么进行位运算结果：
   * 1011 & 1001 = 1001， 1001 & 1001 = 1001；
   * 而如果length是2的次方如：16，则同样对hash值为11和9进行取模结果：
   * 1011 & 1111 = 1011， 1001 & 1111 = 1001
   * 这样，有效避免了hash冲突，保证元素尽可能分布均匀
   *
   */
  static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

  /**
   * The maximum capacity, used if a higher value is implicitly specified
   * by either of the constructors with arguments.
   * MUST be a power of two <= 1<<30.
   */
  static final int MAXIMUM_CAPACITY = 1 << 30;

  /**
   * The load factor used when none specified in constructor.
   * 使用hash取模计算下标，元素分布的频率在hash桶中遵循一个泊松分布，然后0.75是泊松分布较理想的参数
   * 上面注释中还给了一个参考例子，当加载因子是0.75是，发生hash碰撞的桶的元素超过8个的概率为0.00000006几乎不可能。
   * 个人觉得从另一角度：
   * 如果加载因子是0.5那么会浪费一半的内存空间，加载因子是1，这样容量满了再去扩容，很容易造成hash冲突，导致链表过程影响查询效率
   * 所以0.75是一个折中的参数。
   */
  static final float DEFAULT_LOAD_FACTOR = 0.75f;

  /**
   *
   * 链表转成红黑树的阈值
   */
  static final int TREEIFY_THRESHOLD = 8;

  /**
   * 红黑树退化成链表的阈值
   */
  static final int UNTREEIFY_THRESHOLD = 6;

  /**
   * 当当前hash表的容量大于这个阈值时，才会进行链表转成红黑树操作
   * 否则只进行resize
   */
  static final int MIN_TREEIFY_CAPACITY = 64;

// put 方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
      boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 先判断是否为空
    if ((tab = table) == null || (n = tab.length) == 0)
      // 如果空就初始化
      n = (tab = resize()).length;
    // 判断插入的地方是否有人了
    if ((p = tab[i = (n - 1) & hash]) == null)
      // 没有人直接在末尾加入新节点
      tab[i] = newNode(hash, key, value, null);
    else {
      // 判断key是否一样
      Node<K,V> e; K k;
      if (p.hash == hash &&
          ((k = p.key) == key || (key != null && key.equals(k))))
        // 一样就就覆盖，更新操作
        e = p;
      // 不一样说明发生了hash碰撞，进一步判断这个桶是链表还是红黑树
      else if (p instanceof TreeNode)
        // 以红黑树方式添加
        e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
      else {
        // 以链表方式添加
        for (int binCount = 0; ; ++binCount) {
          if ((e = p.next) == null) {
            p.next = newNode(hash, key, value, null);
            // 如果链表长度大于阈值，转成红黑树
            if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
              // 里面进一步判断，如果整个表容量小于64就只进行rehash,不转换了
              treeifyBin(tab, hash);
            break;
          }
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            break;
          p = e;
        }
      }
      if (e != null) { // existing mapping for key
        V oldValue = e.value;
        if (!onlyIfAbsent || oldValue == null)
          e.value = value;
        afterNodeAccess(e);
        // 如果是覆盖就返回老的值
        return oldValue;
      }
    }
    // 最后添加完，判断是否需要resize
    ++modCount;
    if (++size > threshold)
      resize(); // 先扩容现容量的2倍，重新放置元素
    // 为了继承HashMap的LinkedHashMap类服务的
    afterNodeInsertion(evict);
    return null;
  }


// get 方法
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
      // 判断下标位置第一个元素是否符合key
      if (first.hash == hash && // always check first node
          ((k = first.key) == key || (key != null && key.equals(k))))
        // 是就返回第一个
        return first;
      if ((e = first.next) != null) {
        // 不是就接着往下找，判断桶如果是红黑树就用红黑树方式找，如果是链表就按链表找
        if (first instanceof TreeNode)
          return ((TreeNode<K,V>)first).getTreeNode(hash, key);
        do {
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            return e;
        } while ((e = e.next) != null);
      }
    }
    return null;
  }

public class LinkedHashMap<K,V>     extends HashMap<K,V>     implements Map<K,V>
    
 // 使用双向链表和重写了hashMap中3个方法保证顺序：
    // Callbacks to allow LinkedHashMap post-actions
    void afterNodeAccess(Node<K,V> p) { }
    void afterNodeInsertion(boolean evict) { }
    void afterNodeRemoval(Node<K,V> p) { }
    
 // put 方法： put方法没有重写HashMap的put方法，但是重新了其中的几个子的方法：
   Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
    LinkedHashMap.Entry<K,V> p =
        new LinkedHashMap.Entry<K,V>(hash, key, value, e);
    linkNodeLast(p);    // 加到双向链表的末尾
    return p;
  }

void afterNodeAccess(Node<K,V> e) { // move node to last将访问的元素放到链表最后
    
void afterNodeInsertion(boolean evict) { // possibly remove eldest， evict：是否删除旧元素
  LinkedHashMap.Entry<K,V> first;
    // removeEldestEntry给实现者来重写，有机会删除最老的元素，保持一定容量
  if (evict && (first = head) != null && removeEldestEntry(first)) { // removeEldestEntry：return false;
    K key = first.key;
    removeNode(hash(key), key, null, false, true);
  }
}
void afterNodeRemoval(Node<K,V> e) { // unlink remove方法中调用，删除链表中的元素
    
// 重写了get方法：
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
      return null;
    if (accessOrder) // 如果accessOrder为true,则开启LRU策略
      afterNodeAccess(e);
    return e.value;
  }
```

ConcurrentHashMap

```java
public class ConcurrentHashMap<K,V> extends AbstractMap<K,V> implements ConcurrentMap<K,V>, Serializable
    /**
    jdk1.8之前使用分段锁实现，即每个segment负责连续的几个桶，通过对segment加锁的方式实现线程安全，默认的支持并发写数量是16
    jdk1.8通过CAS + syncronized实现并发
    */

/**
   * The default concurrency level for this table. Unused but
   * defined for compatibility with previous versions of this class.
   * 默认支持多少线程进行并发写，在jdk1.7及之前使用segment设计时使用，现在没用了。
   */
  private static final int DEFAULT_CONCURRENCY_LEVEL = 16;

  /**
   * 默认加载因子，同HashMap
   */
  private static final float LOAD_FACTOR = 0.75f;

  /**
   * 默认树化的阈值，同HashMap
   */
  static final int TREEIFY_THRESHOLD = 8;

  /**
   * 默认退化链表的阈值，同HashMap
   */
  static final int UNTREEIFY_THRESHOLD = 6;

  /**
   * 树化的表容量阈值，小于就只进行resize
   */
  static final int MIN_TREEIFY_CAPACITY = 64;


public V remove(Object key)
remove方法跟put方法过程差不多，调用replaceNode方法，先判断是否正在resize,如果是当前线程就进入helpTransfer方法
否则直接使用synchronized加锁，删除成功后，调用addCount(-1, -1)方法计数字。
    
    /** Implementation for put and putIfAbsent */
  /**
   *  如果是第一次put,需要初始化表
   *  如果put位置桶空的，则通过CAS添加新节点
   *  如果put位置桶不为空，但hash状态==MOVED(-1),说明当前表正在进行resize,当前线程进入helpTransfer方法
   *  如果put位置桶不为空，说明桶已经有人了，对当前的桶进行加锁
   *    判断是链表还是红黑树，用对应的方法去添加
   *      如果有相同key则覆盖
   *      没有相同key,添加新节点到后面
   * 调用addCount(int count, int check),count表示新增元素个数，check是链表的长度. 计算并且检查是否需要resize
   */
  final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode()); // 对hashCode再hash,减少hash碰撞
    int binCount = 0; // 统计链表元素个数，判断是否要转成红黑树
    for (Node<K,V>[] tab = table;;) {
      Node<K,V> f; int n, i, fh;
      // 懒加载，第一次put时，初始化表，避免第一次操作就进行resize影响效率，如：putAll
      if (tab == null || (n = tab.length) == 0)
        tab = initTable();
        // 查找桶，是否为空,tabAt内部直接调用UNSAFE.getObjectVolatile获取主内存中的值
      else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
        // 添加空的桶，直接CAS,无需加锁
        if (casTabAt(tab, i, null,
            new Node<K,V>(hash, key, value, null)))
          break;                   // no lock when adding to empty bin
      }
      // hash 为-1，说明当前表状态是正在扩容
      else if ((fh = f.hash) == MOVED)
        // 帮助扩容
        tab = helpTransfer(tab, f);
      else {
        V oldVal = null;
        synchronized (f) { // 要存的桶里已经有人了，对当前桶加锁
          if (tabAt(tab, i) == f) {
            if (fh >= 0) {
              binCount = 1;
              // 如果是链表，以链表方式添加
              for (Node<K,V> e = f;; ++binCount) {
                K ek;
                if (e.hash == hash &&
                    ((ek = e.key) == key ||
                        (ek != null && key.equals(ek)))) {
                  oldVal = e.val;
                  // key是同一个，是否覆盖
                  if (!onlyIfAbsent)
                    e.val = value;
                  break;
                }
                // 不是同一个key,新值加到链表最后
                Node<K,V> pred = e;
                if ((e = e.next) == null) {
                  pred.next = new Node<K,V>(hash, key,
                      value, null);
                  break;
                }
              }
            }
            // 如果是红黑树，以红黑树方式添加
            else if (f instanceof TreeBin) {
              Node<K,V> p;
              binCount = 2;
              if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                  value)) != null) {
                oldVal = p.val;
                if (!onlyIfAbsent)
                  p.val = value;
              }
            }
          }
        }
        if (binCount != 0) {
          // 判断链表是否需要转成红黑树
          if (binCount >= TREEIFY_THRESHOLD)
            treeifyBin(tab, i);
          if (oldVal != null)
            return oldVal;
          break;
        }
      }
    }
    // 参数1表示增加表个数，binCount（链表长度）参数表示是否需要进行resize检查
    addCount(1L, binCount);
    return null;
  }

/**
   * Helps transfer if a resize is in progress.
   * 判断表不为空，并且状态是-1，正在转移
   * 判断正在扩容，并且扩容线程是否满了
   * 通过CAS设置扩容的线程数量+1
   * 调用transfer方法，进行扩容
   */
  final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {
    Node<K,V>[] nextTab; int sc;// 并发扩容的线程数量
    //如果tab不为空并且节点是正在转移的节点
    if (tab != null && (f instanceof ForwardingNode) &&
        (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {
      // 获取表length获取一个标识
      int rs = resizeStamp(tab.length);
      // 判断nextTab和tab都没有并发修改，并且sizeCtl < 0说明还在扩容
      while (nextTab == nextTable && table == tab &&
          (sc = sizeCtl) < 0) {
        // 判断sizeCtl标识符号，不在变化了，扩容结束了，达到最大扩容线程了或者转移下标在<0,扩容结束
        if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
            sc == rs + MAX_RESIZERS || transferIndex <= 0)
          break;
        // 通过CAS,扩容线程+1
        if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
          // 进行转移
          transfer(tab, nextTab);
          break;
        }
      }
      return nextTab;
    }
    return table;
  }


  /**
   * Moves and/or copies the nodes in each bin to new table. See
   * above for explanation.
   * 根据cpu个数，配置的最小步数：16和表长度计算步长，即每次转移多少节点
   * 初始化一个长度为原来2倍的数组
   * 进行转移
   */
  private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
    int n = tab.length, stride;
    // 根据cpu个数和配置的步长（即每次转移多少个节点）计算步长
    // 公式：如果cpu个数>1,步长为表/8/cpu个数，这个结果小于最小值，则用最小值
    if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
      stride = MIN_TRANSFER_STRIDE; // subdivide range
    if (nextTab == null) {            // initiating
      try {
        @SuppressWarnings("unchecked")
        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];// 创建一个原来大小2倍的数组
        nextTab = nt;
      } catch (Throwable ex) {      // try to cope with OOME
        sizeCtl = Integer.MAX_VALUE;
        return;
      }
      nextTable = nextTab;
      transferIndex = n;
    }
    int nextn = nextTab.length;
    ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
    boolean advance = true;
    boolean finishing = false; // to ensure sweep before committing nextTab
    for (int i = 0, bound = 0;;) {
      Node<K,V> f; int fh;
      while (advance) {
        int nextIndex, nextBound;
        if (--i >= bound || finishing)
          advance = false;
        else if ((nextIndex = transferIndex) <= 0) {
          i = -1;
          advance = false;
        }
        else if (U.compareAndSwapInt
            (this, TRANSFERINDEX, nextIndex,
                nextBound = (nextIndex > stride ?
                    nextIndex - stride : 0))) {
          bound = nextBound;
          i = nextIndex - 1;
          advance = false;
        }
      }
      if (i < 0 || i >= n || i + n >= nextn) {
        int sc;
        if (finishing) {
          nextTable = null;
          table = nextTab;
          sizeCtl = (n << 1) - (n >>> 1); // 转移完成，设置原表大小的0.75
          return;
        }
        if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
          if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
            return;
          finishing = advance = true;
          i = n; // recheck before commit
        }
      }
      else if ((f = tabAt(tab, i)) == null)
        advance = casTabAt(tab, i, null, fwd);
      else if ((fh = f.hash) == MOVED)
        advance = true; // already processed
      else {
        synchronized (f) {
          if (tabAt(tab, i) == f) {
            Node<K,V> ln, hn;
            if (fh >= 0) {
              int runBit = fh & n;
              Node<K,V> lastRun = f;
              for (Node<K,V> p = f.next; p != null; p = p.next) {
                int b = p.hash & n;
                if (b != runBit) {
                  runBit = b;
                  lastRun = p;
                }
              }
              if (runBit == 0) {
                ln = lastRun;
                hn = null;
              }
              else {
                hn = lastRun;
                ln = null;
              }
              for (Node<K,V> p = f; p != lastRun; p = p.next) {
                int ph = p.hash; K pk = p.key; V pv = p.val;
                if ((ph & n) == 0)
                  ln = new Node<K,V>(ph, pk, pv, ln);
                else
                  hn = new Node<K,V>(ph, pk, pv, hn);
              }
              setTabAt(nextTab, i, ln);
              setTabAt(nextTab, i + n, hn);
              setTabAt(tab, i, fwd);
              advance = true;
            }
            else if (f instanceof TreeBin) {
              TreeBin<K,V> t = (TreeBin<K,V>)f;
              TreeNode<K,V> lo = null, loTail = null;
              TreeNode<K,V> hi = null, hiTail = null;
              int lc = 0, hc = 0;
              for (Node<K,V> e = t.first; e != null; e = e.next) {
                int h = e.hash;
                TreeNode<K,V> p = new TreeNode<K,V>
                    (h, e.key, e.val, null, null);
                if ((h & n) == 0) {
                  if ((p.prev = loTail) == null)
                    lo = p;
                  else
                    loTail.next = p;
                  loTail = p;
                  ++lc;
                }
                else {
                  if ((p.prev = hiTail) == null)
                    hi = p;
                  else
                    hiTail.next = p;
                  hiTail = p;
                  ++hc;
                }
              }
              ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                  (hc != 0) ? new TreeBin<K,V>(lo) : t;
              hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                  (lc != 0) ? new TreeBin<K,V>(hi) : t;
              setTabAt(nextTab, i, ln);
              setTabAt(nextTab, i + n, hn);
              setTabAt(tab, i, fwd);
              advance = true;
            }
          }
        }
      }
    }
  }
```



```


Collection:
	List:
		ArrayList
		LinkedList
	Set:
		HashSet
		TreeSet
	Queue:
		LinkedBlockingQueue
		
Map:
	HashMap
		1.7: 数组+链表， 头插法
		1.8：数组+链表+红黑树， 尾插法
		扩容机制，默认0.75
		capacity必须是2的幂
		equals和hashCode必须同时重写
	ConcurrentHashMap
	LinkedHashMap
	
	
	
	并发：
	线程之间如何通信：
	实现一个生产者和消费者模型
	synchronized:
		对象：
			对象头：
				Mark Word, 存储对象的HashCode,锁标志和分代年龄
				Class Pointer,对象指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例
				Monitor:
					EntryList
					Owner,指向持有Monitor对象的线程
					WaitSet
			实例数据
			对其填充
		使用：
			代码块：锁住的是括号内的对象， 通过monitorenter和monitorexit锁对象，程序计数器count
			方法上：锁住的是当前调用对象,ACC_SYNCHRONIZED
			静态方法：这个类对象，而不是实例对象
		锁升级过程：偏向锁 -> 轻量级锁（乐观锁） -> 重量级锁
	ThreadLocal
		实现
		get
		put
		内存泄露
		InheritableThreadLocal
		用来解决什么问题，为什么使用
	volatile: TODO

	JUC:
    	Lock
    	CountDownLatch
    	CyclicBarrier
    	TODO:
		
	线程池：
		4种线程池：
			CachedThreadPool
			FixedThreadPool
			SingleThreadPool
			ScheduledThreadPool
		7个参数：
			corePoolSize
			maximumPoolSize
			keepAliveTime
			TimeUnit
			workQueue
			threadFactory
			RejectedExecutionHandler
		如何优雅的指定线程名字
		阿里不建议newCachedThreadPool等方法，建议自己构造原因
		工厂方法
		创建线程几种方式
		线程池运行原理
			状态
			TODO
		使用场景
		怎么尽可能提高多线程并发数
		
		
	
	JVM:
	io
	反射
	
数据库和中间件
	mysql
	zookeeper
	kafka
	redis
	
大数据：
	hadoop:
		hdfs
		mapreduce
		hbase
		yarn
		hive
	spark
		spark core
		spark sql
	flink
		
计算机基础，数据结构和算法
	设计模式
	计算机基础
	数据结构
	算法
```



## 20210621

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.79 TB (18.75%)
			35.23 TB (75.19%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

开发程序对接历史的商品数据

​	21年的数据格式也要兼容		--ok

​	计算一下商品数据		--ok

		1.主观实盘：沪银ag、郑棉cf、豆油y、沥青bu、pta、纸浆sp、螺纹钢rb、玻璃fg、苹果ap、苯乙烯eb、沪镍ni、沪铝al；
		2.策略应急及黑色系：热卷hc、燃油lu、棕榈油p、铁矿石i、焦煤jm、焦炭j、动力煤zc；
		3.剩余品种可按交易所顺序补录主连数据；
夜盘数据进行排序		--ok



今日工作：

20210621

1.开发历史k线程序，支持对历史的商品数据补录

​	兼容21年之前和之后的不同目录日期格式

​	实现对商品日盘和夜盘数据排序，支持夜盘数据的扫描

flink



###################

## 20210622

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.79 TB (18.77%)
			35.22 TB (75.16%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

开发程序对接历史的商品数据

​		测试发送历史数据，稳定不死

​		测试夜盘数据一直loop的问题



规则修改一下，主连数据重新生成



## 20210623

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群			--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.8 TB (18.79%)
			35.21 TB (75.14%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

开发程序对接历史的商品数据

​		测试发送历史数据，稳定不死

​		生成主力代码，copy主力合约

​		测试夜盘数据一直loop的问题，k线算法调一下



规则修改一下，主连数据重新生成



## 20210624

1.每天上班要做的			--ok

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.78 TB (18.74%)
			35.23 TB (75.18%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

开发程序对接历史的商品数据

​		测试发送历史数据，稳定不死

​		生成主力代码，copy主力合约

​		测试夜盘数据一直loop的问题，k线算法调一下

​		增加15年的单元测试，股指和CF

​				修改交易时间



规则修改一下，主连数据重新生成



注意：

1.股指期货2016年之前的交易时间是9:15~15:15

2.动力煤15年改过合约号，TC > ZC

3.郑商所19年才调整过交易时间,夜盘时间21



20210624

今天工作:

1.重新生成股指的主连数据  --正在运行

2.测试商品期货历史补录程序

​		整理和修改历年交易所的交易时间， 股指在16年之前是09:15-15:15， 郑商所在19年之前夜盘是：21：00-23:30

​		兼容数据：动力煤在15年由合约号TC修改为ZC

明天工作：

继续测试商品期货历史补录程序



## 20210625

1.每天上班要做的

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.78 TB (18.75%)
			35.23 TB (75.18%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

开发程序对接历史的商品数据

​		测试发送历史数据，稳定不死

​		生成主力代码，copy主力合约			--ok

​		k线算法？生成的k线不对

​		增加15年的单元测试，股指和CF		--ok

​				修改交易时间							  --ok

开盘前5分钟的数据都要，无论夜盘还是日盘		--ok



规则修改一下，主连数据重新生成		--正在运行



新服务器安装

1.配置网络

2.安装jdk

3.安装

​	zookeeper增加节点			--不需要，用原来的节点

​		动态的增加节点，但要3.5+以上

​		https://blog.csdn.net/admin_15082037343/article/details/100060014

​	hadoop增加节点

​	hbase增加节点

​	slave2:

​		ProcessReport from dead or unregistered node: DatanodeRegistration(10.10.0.15:50010

​	测试

注意：

1.股指期货2016年之前的交易时间是9:15~15:15

2.动力煤15年改过合约号，TC > ZC

3.郑商所19年才调整过交易时间,夜盘时间21



############

## 20210628

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.8 TB (15.88%)
			35.23 TB (75.18%)
	检查进程， 下面一个都不能少：
		

            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer

jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	如果有问题，启动：hbase-daemon.sh start thrift2

CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


```



1.商品历史数据补录

​		股指+商品历史数据补录，股指21年的补完，15年的要重新处理

​		丢失数据补录



2.hbase新服务器安装， thrift分解掉用



20210628

今日工作

1.hbase服务器

​		系统安装		--ok

​		hbase服务安装		--ok

​		安装多台thriftserver

​				端口转发：

​			

```
1.安装 rinetd

sudo` `apt-get ``install` `rinetd

2.配置rinetd,增加端口转发规则
 	vim /etc/rinetd.conf
	# 在最后添加以下配置
	0.0.0.0 3388 127.0.0.1 3389  # 将本机3388端口转发到3389
	# 启动转发进程：
	rinetd -c /etc/rinetd.conf
	# 确认
	netstat -anp | grep 9091
tcp        0      0 0.0.0.0:9091            0.0.0.0:*               LISTEN      14519/rinetd
```

ngixn的：

https://blog.51cto.com/moerjinrong/2287680



2.周五夜盘数据补录		--ok

​	

明天工作：

安装多台thriftserver 分解调用

​		thrift服务是一个rpc协议，并不是

商品历史数据补录



## 20210629

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.8 TB (15.88%)
			35.23 TB (75.18%)
	检查进程， 下面一个都不能少：
		

            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer

jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	如果有问题，启动：hbase-daemon.sh start thrift2

CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


regionserver OOM了
2021/06/29 07:09:24 INFO  [hconnection-0x1e1dd28-shared--pool1-t27770] - #370516, table=hznc_mkdata:2sdata, attempt=13/35 failed=175ops, last exception: java.io.IOException: com.google.protobuf.ServiceException: java.lang.OutOfMemoryError: Java heap space on slave1,60020,1622529106503, tracking started null, retrying after=20155ms, replay=175ops


 Left over 9 task(s) are processed on server(s): [slave1,60020,1622529106503]
```



1.thrift分解掉用

nginx 健康检查， 模块：nginx_upstream_check_module		--ok

```

        upstream hbase_thrift2_servers {
                server hadoop01:9090 weight=6 max_fails=3 fail_timeout=3s;
                server slave3:9090 weight=2 max_fails=3 fail_timeout=3s;
                server slave4:9090 weight=2 max_fails=3 fail_timeout=3s;
        }

        server {
                listen 9092;
                proxy_pass hbase_thrift2_servers;

        }

}

```

提交一下		--ok

master 端口改为9090		--ok



盘后：

2.商品历史数据补录

​		股指历史数据补录，15年和21年的

​			解压21年的和15年的		--ok

​			发送21年的

​			发送15年的

​		商品历史数据补录

​				ag,cf,y,bu,pta,sp,rb,fg,ap,eb,ni,al,hc,lu,p,i,jm,j,zc,tc,c

​				检查15年的			--ok

​				解压并继续发送15年的

​				解压16年的

​	

3.hbase regionserver		--ok

​		删除datanode

​		删除逻辑卷轴

​		重启datanode

​		重启regionserver



20210629

今天工作：

1.商品历史数据补录

2.安装多台hbaes thrift 通过配置nginx 分解调用		--ok

明天工作：

1.继续历史商品数据补录， 

2.升级实时k线程序，对接新的主力切换规则



############

## 20210630	

```
1.检查下hadoop集群, hbase集群			--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			66.2 TB
			8.83 TB (13.35%)
			53.4 TB (80.66%)
	检查进程， 下面一个都不能少：
		

            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer

jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	如果有问题，启动：hbase-daemon.sh start thrift2

CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.商品历史数据补录

​		股指历史数据补录，15年和21年的

​			解压21年的和15年的		--ok

​			发送21年的		--ok

​			发送15年的

​		商品历史数据补录

​				ag,cf,y,bu,pta,sp,rb,fg,ap,eb,ni,al,hc,lu,p,i,jm,j,zc,tc,c

​				检查15年的			--ok

​				解压并继续发送15年的

​				解压16年的

导入太慢了，换种方式，直接生成hfile:

​	Bulkload 

​	https://blog.csdn.net/xiaohu21/article/details/108310612



3.升级实时k线程序

​			升级实时k线程序			--ok

​			手动插入主力代码的记录		--ok



20210630：

今天工作：

1.商品历史数据补录

2.升级实时k线程序，对接新的主力切换规则		--ok

明天工作：

1.继续商品历史书补录



############

## 20210701

```
1.检查下hadoop集群, hbase集群			--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			66.2 TB
			8.9 TB (13.44%)
			53.34 TB (80.57%)
	检查进程， 下面一个都不能少：

            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer

jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123 
	进程：datacenter-realtime-futures		晚上八点
    	  
	     
3.检查界面，行情软件
	如果有问题，启动：hbase-daemon.sh start thrift2

CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```

1.商品历史数据补录

​		商品历史数据补录

​				ag,cf,y,bu,pta,sp,rb,fg,ap,eb,ni,al,hc,lu,p,i,jm,j,zc,tc,c

​				检查15年的			--ok

​				解压并继续发送15年的

​				解压16年的

导入太慢了，换种方式，直接生成hfile:

​	Bulkload 

​	https://blog.csdn.net/xiaohu21/article/details/108310612

​		先生成csv		--ok

​		上传到hdfs

​				创建目录：

​						hdfs dfs -mkdir -p /csv/input/2015

​				上传：

​						hdfs dfs -put hznc_mkdata-tickdata.csv /csv/input/2015

​				查看：

​						hdfs dfs -ls /csv/input/2015

​		hbase shell 生成hfile文件

```shell
hbase  org.apache.hadoop.hbase.mapreduce.ImportTsv \
-Dimporttsv.separator=, \
-Dimporttsv.columns='HBASE_ROW_KEY,cf_data:01cSymbol,cf_data:02dbClosePrice,cf_data:03dbHeightPrice,cf_data:04dbLowPrice,cf_data:05dbOpenPrice,cf_data:06dbSum,cf_data:07dbYTClosePrice,cf_data:08uTime,cf_data:09uVolume,cf_data:10uVolume_Sell,cf_data:11zpos,cf_data:12zpos_diff,cf_data:13avgPrice,cf_data:14tdHighestPrice,cf_data:15tdLowestPrice,cf_data:16UpperLimitPrice,cf_data:17LowerLimitPrice,cf_data:18BidPrice1,cf_data:19BidVolume1,cf_data:20AskPrice1,cf_data:21AskVolume1,cf_data:from'  \
-Dimporttsv.bulk.output=/csv/output/2015 \
hznc_mkdata:tickdata \
/csv/input/2015
```

​		

没有权限：

```
Exception in thread "main" org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=EXECUTE, inode="/user/root/.staging/job_1625124755907_0002":hadoop:supergroup:drwx------
        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:320)
```



需要启动web-proxy:

yarn-daemon.sh start proxyserver

查看mr任务：

yarn application -list

杀掉任务：

yarn application -kill application_1625127398446_0003



实时k线程序本地内存溢出了？

```java
// Something really bad happened. We are on the send thread that will now die.
LOG.error("Internal AsyncProcess #" + id + " error for "
    + tableName + " processing for " + server, t);
throw new RuntimeException(t);
```

是否可以调节线程的大小

32 位 windows增加内存？



20210701

今天工作：

1.商品历史数据补录

​		准备修改程序，换个方式导历史数据：

​					1.修改程序将各周期数据生成本地csv		--ok

​					2.收盘后调用hbase自带的importTsv工具将csv转换成hbase基础文件hfile		--正在测试中

​					3.增量导入hfile文件

2.商品历史数据补录  --ok

明天工作：

1.测试hbase BulkLoad导入数据方式

2.补录股指历史数据，由于合约全称化升级导致6.1-6.17数据缺失



2.线程池





并发编程:

LinkedBlockingQueue

CopyOnWriteArrayList



todo:

jstat, qps

查看连接:

netstat -anp | grep 8080 -c

查看进程的线程数：




    hbase优化：
    1.生产环境下关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。
    一般生产环境下为了避免影响读写请求，会禁用自动触发major compaction。
    2.使用数据块编码


补k线程序有个小bug,kbug:11:29:59 , tick:13:00:01,那就会漏掉13:00:00的k线



学习搭建和使用hive

hbase 版本：1.3.1

hadoop版本：2.7.3







3.归并排序？

​	Blockingqueue



todo:

nagios

新的项目架构：

​	kafka + redis + flink + hbase

学习：

​	hive + spark + hadoop

源码：

​	kafka, hbase

SPI ,serviceLoader

hbase性能测试，吞吐量如何？

用flink去实现k线合并的程序

装一套hive,跟hbase集成

装一套监控的系统

看看：

开仓，平仓

盘面资金

大单数据

北向资金

策略

主力合约Tick数据

股指

期权

股票的开盘时间

主连

股票



代码问题：

​	日志问题，直接System.println.out

​	配置文件，ip端口直接写死的

​	打出来的jar包是用eclipse导出来的，应该用mvn install

​	依赖的jar包直接提交了

​	代码格式化问题，格式太乱，大量重复代码，没有用到的变量。

​	单元测试



## TODO



LinkedBlockingQueue 线程安全

算法和计算机原理

flink

clickhouse

mysql

数据仓库








​	