## tips

释放buffer/cache的内存：

```
释放缓存区内存的方法
sync# 将内存中数据同步到磁盘

 a）清理pagecache（页面缓存）

# echo 1 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1

　 b）清理dentries（目录缓存）和inodes
# echo 2 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2
　 c）清理pagecache、dentries和inodes

# echo 3 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3

# 如何限制buffer/cache的占用？
```

注意：

夜盘数据比较特殊,  比如 2021-04-01 21:00:00 ~ 2021-04-02 00:00:00 的数据, 其实是 2021-03-31 21:00:00 ~ 2021-04-01 00:00:00 的数据.  即夜盘一整天的开盘时间是 昨天 21:00

maven 官方下载地址：

https://archive.apache.org/dist/maven/maven-3/

服务器地址：

```
10.10.10.104   administrator  Admin123
10.10.10.102 administrator  Admin711406
```



这个SVN地址是你的私人地址，你可以提交任何临时代码。
：https://10.10.10.102/svn/private_source/wangtao
账户名和密码是名字全拼。

项目 SVN 地址:
https://10.10.10.102/svn/量化系统/nc_tree_parse/nc_algo

confluence 地址：http://10.10.0.47:8090/

​	ftp:list_delete_rowkey.shb

	   历史股指期权 和 商品期权 数据的下载地址 ：
	   域名：tik-ftp.citicsf.com 端口：8371
	   电信IP：58.33.80.163     端口：8371
	   联通IP：140.206.97.123 端口：8371
	   李佳桧/83g3Mh7m

​	历史数据：

​		50ETF期权数据
​		CFFEX股指期货
​		DCE大连商品
​		CZC3郑州商品
​		SHFE上海商品

钉钉邮箱：wangdao6551@dingtalk.com

能诚账号：u00479密码：1

jira账号：u00479/123456

jira   ip地址更换成：http://10.10.0.47:8080/

svn账号和密码：liuzhenjiang/liuzhenjiang

hbase:
	hadoop-daemon.sh start datanode
	hbase-daemon.sh start regionserver
	tail  -n -500 /usr/local/hbase/logs/hbase-hadoop-regionserver-slave4.log

sql server:
		properties.setProperty("user", "R16");
		properties.setProperty("password", "R16_0625");

现有集群规模：共有七台机器，老机房两台，新机房五台。

老机房两台：

​     主机名：keep-0        IP：10.10.10.110    nc_007用户登录密码：nc_007

主机名：keep-1        IP：10.10.10.111       nc_008用户登录密码：nc_008

 ![image-20210510085345685](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210510085345685.png)

新机房五台：

​     主机名：master      IP：10.10.0.254        root用户登录密码：1

主机名：slave1        IP：10.10.0.119        root用户登录密码：1

主机名：slave2        IP：10.10.0.54        root用户登录密码：1

主机名：slave3        IP：10.10.0.253        hadoop用户登录密码：1

主机名：slave4        IP：10.10.0.252        hadoop用户登录密码：1

 

集群配置：

​     三台zookeeper，七台HDFS（master，slave1，上运行namenode，七台DataNode）

​     Master，slave3作为HBASE的HMaster节点，除master节点之外，六台起HRegionserver服务，HMaster节点需要另起ThriftServer服务来提供读取数据服务。集群启动步骤见《集群各项服务启动命令.txt》文件

Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas

HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview



git key: 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



## 每天做的

```
1.检查下hadoop集群, hbase集群
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：RunOnlyGuzhi，
    	  
10.10.10.102 administrator/Admin711406  
	进程：GetMarketDataAndStore
	     GuPiaoReduce（RunDataMerge?）
```



###################

## 20210601

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
	
```



2.继续股指历史数据补录

​	进程oom的问题

 [hconnection-0x1b03244-metaLookup-shared--pool3-t31] - Call exception, tries=10, retries=16, started=47592 ms ago, cancelled=false, msg=Call to vm01/192.168.198.101:16201 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: no further information: vm01/192.168.198.101:16201, details=row 'hznc_mkdata:2sdata,IF1503_1420508812,99999999999999' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=vm01,16201,1622451944197, seqNum=-1, see https://s.apache.org/timeout



​	单元测试改成离线的也能正常运行

​	支持继续发送

hbase 不断自动的split?

因为过大的内存会导致GC时间过长（GC方式从CMS改为G1后可以增大该值，机器内存足够的情况下可以翻倍甚至更大）。 ((RS Xmx) *hbase.regionserver.global.memstore.size) / (hbase.hregion.memstore.flush.size *(# column families))。      *

* 即16G*0.45/128M=64个





补数据：

get "hznc_mkdata:tickdata", "IC06_1622528746_0"



20210601 14:26:00 没有补数据？



一些表设置了TTL？ 整理下

用新的表测试？

create 'hznc_mkdata','cf_data'



create "hznc_mkdata:tickdata_his", {NAME => "cf_data", VERSIONS => 1, COMPRESSION => "snappy", BLOCKCACHE => "TRUE"}

create "hznc_mkdata:ddata_his", {NAME => "cf_data", VERSIONS => 1, COMPRESSION => "snappy", BLOCKCACHE => "TRUE"}



## 20210602

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？
			2021-05-28 09:55:47 INFO  [pool-1-thread-10] - id=1, table=hznc_mkdata:2sdata, attempt=6/16, failureCount=12ops, last exception=org.apache.hadoop.hbase.exceptions.RegionMovedException: Region moved to: hostname=master port=60020 startCode=1620695541020. As of locationSeqNum=8744807. on keep-1,60020,1620609114035, tracking started null, retrying after=2008ms, operationsToReplay=12
			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: org.apache.hadoop.hbase.exceptions.RegionOpeningException: Region hznc_mkdata:1sdata,fu08_1615959832,1621346558611.dfff89a834f62426a1fef4aa1c1ff9e0. is opening on slave3,60020,1619400396937
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2972)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1140)
	at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2197)
	at 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	
	
	toSqlserver程序
```



补数据程序做个版本

​	参考文档《数据修订和核对流程.md》

​	检查各个子进程		--ok

​			todo: datasource, 先用日志观察

  1.修订的程序不要在本地运行了，升级到线上服务器，在线上的服务器进行补录

  2. 代码分支管理：

       	建两个分支，dev分支和master分支。开发在dev分支上，开发完成测试通过合并到master

     ​	master运行稳定一周后，打一个tag， 升级版本。

3.实时k线，包含15:00的？  --好像是客户端的问题？

​	scan "hznc_mkdata:5mindata", {STARTROW => "IF2106_1622595600", ENDROW => "IF2106_1622619000"}



2.继续历史股指补录

​		

3.TTL的问题

​		

4.数据补录的问题

​		1.数据发重复了？		--没有，看错了

​		2.k线合并有问题，价格不对

​		3.数据发不进去？ 时间戳不对还是刷新缓存

```
if (HISTORY_SPIF_HBASE.equals(runMode) && false) {
  put.addColumn(
      family, qualifier, ts, // 历史数据时间戳用历史的，方便删除
      value);
```



​		4.java64 加载不了native库？		--使用32位java

​		5.历年的休假时间

```
数据补录的会议：
1.跟中信确认下生成时间

2.策略部，后面找一下是否可以包含成交量为0的数据

3.昨日收盘价格用程序去读


数据核对：
查询tick的数据跟源文件中对比一致，可以程序去对比

每个合约不同交易时间，k线个数不一样，可以动态的去对比


开发补数据完通知到测试，测试通知到策略部

补录数据反馈要及时

自动化完成之前每日收盘开发跟测试验证数据

后面自动化：
补数据时，客户端可以提示数据异常，正在补录。

王涛：
程序兼容两种格式
补录程序部署到线上
分支标准化
补数据的流程化

吴凯伦：
程序稳定性，测试
导出格式固定

```





今天工作：

20210602

补录程序的问题修改，合并k线测试

补数据流程文档



## 20210603

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.3 TB (17.72%)
			35.72 TB (76.22%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```

​	regionServer释放内存？

释放buffer/cache		--ok

如何限制buffer/cache 的占用？

AP220没有9:00跟9:01的k线？1min

scan "hznc_mkdata:1mindata", {STARTROW => "AP2201_1622682000", ENDROW => "AP2201_1622682180"}



查一下早上8点-8点半的

scan 'hznc_mkdata:1sdata', {TIMERANGE => [1622678400000, 1622680800000]}



可能要把8：55之前的数据屏蔽掉		--ok

2021-06-03 08:00:02 INFO  [store-tick] - store tick: FG106_1622732393_0 ok, count: 6725
2021-06-03 08:00:03 INFO  [store-tick] - store tick: au2202_1622658600_1 ok, count: 6726



2.补录程序修改：

​	1.带时间戳发不进去？调试一下		--ok，去掉，不使用时间戳了

​	2.补录程序发布版本更新上线

​			自动查询前一天的收盘价		--ok

​			优化保证稳定不死

​					calendar.setTime(new Date(ts)) -> calendar.setTimeImillis(ts);

​					updateKline 去掉clone方法

​					string[] splits = line.split(",") 改成直接统计了

​			历年的休假时间，节假日时间，从国务院官网爬取的：			--ok

​					https://github.com/NateScarlet/holiday-cn/blob/master

​			jna是否可以固定线程

​		可能要把8：55之前的数据屏蔽掉		--ok

盘后检查数据的程序，k线		--ok

​	3.本地运行		--ok



TTL修改，先找一个表测试		--ok

hznc_mkdata:1sdata：   无

​		'hznc_mkdata:2sdata', {NAME => 'cf_data', TTL => '2592000 SECONDS (30 DAYS)'}

​		'hznc_mkdata:3sdata', {NAME => 'cf_data', TTL => '2592000 SECONDS (30 DAYS)'}

​		hznc_mkdata:5sdata', {NAME => 'cf_data', TTL => '3888000 SECONDS (45 DAYS)'}

​		'hznc_mkdata:10sdata', {NAME => 'cf_data', TTL => '5184000 SECONDS (60 DAYS)'}

​		'hznc_mkdata:15sdata', {NAME => 'cf_data', TTL => '5184000 SECONDS (60 DAYS)'}

​		'hznc_mkdata:30sdata', {NAME => 'cf_data', TTL => '7776000 SECONDS (90 DAYS)'}

​		'hznc_mkdata:1mindata', {NAME => 'cf_data'}		无

​		'hznc_mkdata:5mindata', {NAME => 'cf_data'} 	无

​		'hznc_mkdata:15mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:30mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:60mindata', {NAME => 'cf_data'}	无

​		'hznc_mkdata:ddata', {NAME => 'cf_data'}	无

hznc_mkdata:tickdata  365天

如果修改也比较简单，但要再盘后修改，因为要先disable掉表：



​	describe "hznc_mkdata:ticidata" # 查看确认下表结构

​	disable 'hznc_mkdata:tickdata' # 先禁用表

​	alter 'hznc_mkdata:tickdata' , {NAME=>'cf_data',TTL=>'2147483647', COMPRESSION => "snappy"}  # 不删除,使用压缩

​	enable 'hznc_mkdata:tickdata'  # 恢复表



disable 'test_xiao' # 先禁用表

​	alter 'test_xiao' , {NAME=>'test_xiao',TTL=>'2147483647', COMPRESSION => "snappy"}  # 不删除,使用压缩

​	enable 'test_xiao'  # 恢复表





今日工作：

20210603

离线补录程序的修改和完善：

​	统计和支持加载历年的节假日日期

​	开发简单的程序自动检查盘后实时数据





###################

## 20210604

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.54 TB (18.22%)
			35.48 TB (75.72%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2
		地址已经在使用：


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

问一下数据库监控

			
			tick数据到58秒，1s数据到53秒？两个问题：
				1.一个补数据没有生效，endTs应该是后一天的				--ok,已经修复，明天再验证下
				2.5 3秒后的数据是早上8点推过来的，数据源有问题。
			
			
			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```



2.继续开发历史数据补录程序

​	日志按照天输出		--ok

​			log4j:WARN No such property [datePattern] in org.apache.log4j.RollingFileAppender. 不支持属性datePattern

​			log4j.appender.main=org.apache.log4j.DailyRollingFileAppender  不支持属性maxFile

​	补录程序稳定不死

​			Exception in thread "main" java.lang.IllegalStateException: Queue full

​			jprofile 调一下

​				最大内存：512M

​		线程卡住了?

​		

``` s
if (tickData.Volume < 0 || tickData.Amount < 0) {
  return;
}
是负的？
```



```
2021/06/04 11:27:06 INFO  [store-tick] - store tick: IF1502_1422845600_0 ok, count: 131203
2021/06/04 11:27:06 INFO  [store-tick] - store tick: IF1502_1422845600_1 ok, count: 131204
```



​	离线数据的单元测试		--ok





###################

## 20210605

1.历史数据补录

​		线程卡死的问题，看看是不是linkedBlockingqueue导致的

​			poll方法？

java.lang.NullPointerException
	at com.hznc.datacenter.task.MergeAndStore.updateKParam(MergeAndStore.java:179)
	at com.hznc.datacenter.task.MergeAndStore.getParam(MergeAndStore.java:165)
	at com.hznc.datacenter.task.MergeAndStore.mergeAndStoreKline(MergeAndStore.java:152)
	at com.hznc.datacenter.task.MergeAndStore.run(MergeAndStore.java:110)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)



线程死掉了，死掉怎么不说？			--ok



发送起来：

8.47 TB (18.08%)，  35.55 TB (75.87%)



```
kCycle  1420394399 应该是：
```

：1420394400 -1



###################

## 20210607

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.57 TB (18.28%)
			35.45 TB (75.66%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```





2.离线数据补录

​		TF这些是否要发？		--ok, 发送

​		部署到线上环境			--ok

​		检查下，日志中的报错，是否可以优化

​			又是这个问题：

		2021/06/07 09:11:50 WARN  [Default-IPC-NioEventLoopGroup-1-8] - A task raised an exception. Task: org.apache.hadoop.hbase.ipc.NettyRpcConnection$6$1@18a34f1
		java.lang.OutOfMemoryError: Java heap space
	
	​					2021/06/07 09:11:50 WARN  [Default-IPC-NioEventLoopGroup-1-6] - Unexpected exception in the selector loop.
	​					java.lang.OutOfMemoryError: Java heap space
	
	​					waiting for 1000  actions to finish on table
	
	表在split时引起的？
	每次写的批量太大引起的？ 计算puts的大小：
		2737776 byte  2.6MB
	默认的pool大小？
	
	    ThreadPoolExecutor tpe = new ThreadPoolExecutor(
	        coreThreads,   // 256, 如果是获取meta表128
	        maxThreads,    // 256, 如果是获取meta表128
	        keepAliveTime, // 60
	        TimeUnit.SECONDS,
	        workQueue, // LinkedBlockingQueue
	        Threads.newDaemonThreadFactory(toString() + nameHint));
	    tpe.allowCoreThreadTimeOut(true);
	    使用默认的，测试一下


​	    
​	    检查实时数据：
​	    ic: 			策略：25891       数据中心：25888	监控中心：25888
​	    ih: 			策略：25087       数据中心：25084	监控中心：25084
​	    if:				策略：27769       数据中心：27766	监控中心：27766


​			

​		实时k线重启一下		--ok

​		补录一下周五的日k		--ok



3.继续安装hive

​	安装mysql



动态规划





今日工作：

20210607

1.历史股指数据补录

​	已经发完2015-2016年的数据

2.盘后补录程序线上部署		--ok



###################

## 20210608

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.68 TB (18.53%)
			35.34 TB (75.42%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
```



2.股指历史数据继续发送

​	2015		--ok

​	2016		--ok

​	2017	--ok

​	2018	--ok

​	2019

​	2020

​			IO2002-C-3550 这个合约？先去掉， 后面有需要再发

​	在线上环境运行了，本地太占资源

​	写个删除的程序， 输入合约代码 + 开始时间 + 结束时间

​		1.从文件查找列出所有要删的合约代码， 要删除的表，tick + 日k线

​		2.scan查询要删除的行（没有from:dc属性的）

​		2020-2021.5.12

3. 6.4日，周五的夜盘数据切换到6.7日，周一的夜盘了？		--ok, 时间戳直接使用utime字段，不用交易日取日期

​	日期使用的是这个字段： byte[] TradingDay = new byte[8]; // 交易日    工作日



4.补一下商品数据：			--ok

c2109，jm2109 , j2109 , ZC109 , i2109

6月3号21点到6月7号21点

1622725200 - 1623070800

5.升级程序				--ok

​	晚上观察一下



2021-06-08 14:10:00    1623132600

2021-06-08 14:15:00

hbase 手动维护compaction?



 c2109_1623078000_0                                          column=cf_data:from, timestamp=1622818805177, value=dc
11248 row(s) in 26.0450 seconds



今日工作：

20210608

1.股指历史数据继续发送

​			2017-2018已经发完成

2.修复夜盘数据时间错乱的问题

3.商品数据补录



## 20210609

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.68 TB (18.53%)
			35.34 TB (75.42%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件			--ok
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33


			有延迟？			
			exception=org.apache.hadoop.hbase.exceptions.RegionOpeningException: 
	
	region达到一定的大小开始分裂，分裂成两个region,hbaes有自动的regionBalance功能，这个过程会移动region导致region的下线和重新上线
	1.解决办法就是可以预分区，预分region
	2.关闭自动的split和rebanlace,在没有数据的时候去检测有超过20g的就split
	
	
	查看硬盘有没有做raid
	cat /proc/mdstat
	对master节点来说，使用raid主要是为了保护关键性的文件系统数据，通常的配置是raid1+0或者raid0+1
	

	toSqlserver程序
	
	行情界面查询的数据跟hbase不一致？
	
	大商所的时间有问题			--不用处理了，肖兵那边处理
		判断当前日期跟tick日期
	
	程序卡死的问题？     开会的时候程序卡死了？  好像还是有脏数据推过来
		过滤到8:59

```





1.程序卡死的问题？		--ok

​		开会的时候程序卡死了？  好像还是有脏数据推过来, 过滤掉59分



3.写个程序删除旧数据

​		盘后, 等客户端切换成全称后再删除吧

​		tick数据没有生成？？？ 应该是只有19年的

​				storeTickEnable=false



​		清除6.9 21-23的数据			--ok

​				批次修改成500好像更加稳定？

​		继续补录21年的数据

​				

```
报错：
2021/06/09 15:26:33 INFO  [pool-1-thread-3] - id=1, table=hznc_mkdata:tickdata, attempt=11/16, failureCount=1000ops, last exception=org.apache.hadoop.hbase.RegionTooBusyException: org.apache.hadoop.hbase.RegionTooBusyException: Above memstore limit, regionName=hznc_mkdata:tickdata,IF1903_1537250654_0,1623223472026.b00302f355fec13c4895006572066f10., server=slave3,60020,1619400396937, memstoreSize=269743272, blockingMemStoreSize=268435456
        at org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:3784)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2967)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2918)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doBatchOp(RSRpcServices.java:823)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.doNonAtomicRegionMutation(RSRpcServices.java:785)
        at org.apache.hadoop.hbase.regionserver.RSRpcServices.multi(RSRpcServices.java:2239)
        at org.apache.hadoop.hbase.protobuf.generated.ClientProtos$ClientService$2.callBlockingMethod(ClientProtos.java:34958)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2339)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:123)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:188)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:168)
 on slave3,60020,1619400396937, tracking started null, retrying after=10081ms, operationsToReplay=1000
```



4.主力切换规则

​	先看看如何生成



5.简单使用hive,创建hive 和hbase的表关联		--ok

​	学习hive常用的语句，哪些会触发mr任务

WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.



今天工作：

20210609

1.股指历史数据补录

​		2015年-2020年的股指数据已补完

2.修复大商所夜盘商品数据时间错乱的问题

3.期货主力合约计算程序 ， 还在设计中



## 20210610

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群	
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发



3.程序早上没有重启，开盘有问题？

​		还是要早晚重启？不然不太稳定



4.检查下数据，股指历史数据补录的

​		实时发送，批次改成100看是否有延迟, 还是有1-2分钟的延迟

​		修改成500应该没有问题



今日工作：

20210610

期货主力规则切换算法开发

实时期货数据检查		--ok



5.

String, StringBuffer和StringBuilder

> ```java
> public final class String
>     implements java.io.Serializable, Comparable<String>, CharSequence { // final修饰，表示不可继承
>     /** The value is used for character storage. */
>     private final char value[]; // 存储字符，final修饰，一旦赋值就不能重新引用对象
> 
>     /** Cache the hash code for the string */
>     private int hash; // Default to 0
> 
>     /**
>     String 是一个特殊的类：
>     1.使用“+” 拼接字符串时，jvm在编译时进行优化，如果是字符串常量拼接，编译后直接是拼接后的结果，如：
>     String value = "hello" + "world"; 编译后：String value = "helloworld";
>     如果不是常量拼接，编译后会转换成StringBuilder进行拼接：
>     String value = "count" + i; 编译后：String value = new StringBuilder("count").append(i);
>     
>     2. 如果直接String value = "helloworld";方式创建字符串，编译期间JVM就会到字符串常量池检查是否有字符串对象，没有就创建放到常量池，然后返回。
>     而    String value = new String("helloworld"); 编译期间检查字符串常量池中是否有“helloworld”，没有就创建。运行期间直接在堆中创建对象，然后返回堆中对象的引用。所以可能创建一个对象也可能两个。
>     
>     3.字符串常量池
>     jdk1.8前后有区别， 1.8之前常量池在永久代(permGen),1.8及之后再堆内存中。
>     顺便提一下，1.8之后永久代被元空间替代，跟堆内存在一起。
>     4.intern方法
>         intern方法的注释已经很好的说明了intern方法的执行逻辑：When the intern method is invoked, if the pool already contains a string equal to this object as determined by the equals method, then the string from the pool is returned. Otherwise, this object is added to the pool and a reference to this object is returned。All literal strings and string-valued constant expressions are interned。
>     简单翻译一下就是分以下三个情况：
>     1.执行intern方法时，如果字符串常量池中已经包含执行intern方法的String对象，则直接返回字符串常量池中的String对象；
>     2.执行intern方法时，如果字符串常量池中不包含执行intern方法的String对象，则先将该String对象添加到字符串常量池中，然后将字符串常量池中的String对象返回；
>     3.字符串字面常量（literal strings，如"a"，"b"）和字符串常量表达式（string-valued constant expressions，如"a" + "b"）也都要放到字符串常量池中。
>     随着虚拟机结构的调整，intern执行的结果在情况2下有些差异。Jdk1.6中的字符串常量池是放在永久代（Perm）区中的，永久代（Perm）区和正常的 JAVA堆（Heap ）区域是完全分开的。上面说过literal strings 和 string-valued constant expressions会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap区域。而Jdk1.8取消了永久代（Perm），字符串常量池就从 Perm 区移到正常的Java Heap 区域了。由于上面的调整，导致intern方法执行结果在jdk1.6和1.8下存在差异。
>     }
> 
>     private static void callInternMethodStringPoolNotExist() {
>         String value = String.valueOf('a');
>         String valueIntern = value.intern();
>         System.out.println(value == valueIntern);
>     }
>     Jdk1.8版本下，执行结果打印true。执行过程如下：
>     1.String value = String.valueOf('a')，'a'是primitive type，数据直接存储在栈上。然后再创建一个新的String对象value，value的内容为"a"，执行完常量池中并没有值为"a"的对象；（注意：如果直接String value = new String("c");执行首先检查常量池有没有，没有就创建，然后堆中创建一个对象）
>     2.执行String valueIntern = value.intern()，此时常量池里中还没有字符串"a"对象了，而Jdk1.8字符串常量池就在堆区，可以直接拿到value的引用，放到常量池中，然后返回value的引用，赋值给valueIntern；
>     3.System.out.println(value == valueIntern)，打印true，因为value和valueIntern都指向value的引用。*/
>     
>    
>    
> StringBuilder:
> public final class StringBuilder  extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 因为string是不可变的，所以提供可变的StringBuilder,来操作字符串
> public StringBuilder() { super(16);} // 默认的capacity是16
>     
> public StringBuilder(String str) { super(str.length() + 16);   append(str);} //始终保持16长度的空余 
>     
>  append方法：
>      public AbstractStringBuilder append(String str) {
>         if (str == null)
>             return appendNull();
>         int len = str.length();
>      	// 如果容量不够则创建足够容量的字符数组，然后通过System.arraycopy的方式填充
>         ensureCapacityInternal(count + len); 
>         str.getChars(0, len, value, count);
>         count += len;
>         return this;
>     }
>     
> StringBuffer:
> public final class StringBuffer    extends AbstractStringBuilder    implements java.io.Serializable, CharSequence
> // 跟StringBuilder一样都继承自AbstractStringBuilder类，但对几乎所有方法都进行重新加上了synchronized修饰方法
>         
> ```



​	threadLocal 和ineritableThreadLocal



```java
    public void set(T value) {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null)
            // 当前的threadLocal对象为key,保存到线程的成员变量ThreadLocalMap中去
            map.set(this, value);
        else
            createMap(t, value); // t.threadLocals = new ThreadLocalMap(this, firstValue);
    }   


public T get() {
        Thread t = Thread.currentThread();
        // 每个线程内维护ThreadLocalMap的成员变量，key是当前ThreadLocal对象
        ThreadLocalMap map = getMap(t); // return t.threadLocals
        if (map != null) {
            /**
            To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys
            */
            ThreadLocalMap.Entry e = map.getEntry(this); // Entry是一个弱应用
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue(); // 初始化<Thread.currentThread(), null>，然后返回value: null
    }


      private Entry getEntry(ThreadLocal<?> key) {
          // 用当前threadLocal对象的hashcode和table进行取模计算下标
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.get() == key)
                return e;
            else
                return getEntryAfterMiss(key, i, e); // 发生hash碰撞后，并不是以链表形式去保存和取，而是取下标的后一位：nextIndex(i, len)
        }

public class InheritableThreadLocal<T> extends ThreadLocal<T> {}// 子线程可继承的ThreadLocal
    
//  Thread的init方法中：
  this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
// 再看看createInheritedMap：
return new ThreadLocalMap(parentMap);

// 实现可继承ThreadLocalMap的构造方法
  private ThreadLocalMap(ThreadLocalMap parentMap) {
      		// 根据父类ThreadLocalMap初始化子类的Table,就是一个Entry数组
            Entry[] parentTable = parentMap.table;
            int len = parentTable.length;
            setThreshold(len);
            table = new Entry[len];

            for (int j = 0; j < len; j++) {
                Entry e = parentTable[j];
                if (e != null) {
                    @SuppressWarnings("unchecked")
                    ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();
                    if (key != null) {
                        Object value = key.childValue(e.value); // return value; 这个key实际是InheritableThreadLocal, 实现了childValue,而ThreadLocal没有实现的。
                        Entry c = new Entry(key, value);
                        int h = key.threadLocalHashCode & (len - 1);
                        while (table[h] != null)
                            h = nextIndex(h, len);
                        table[h] = c;
                        size++;
                    }
                }
            }
        }

```



LinkedBlockingQueue



## 20210611

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```





2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[T152_151LOG]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_tme] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


```

3.程序早上没有重启，开盘有问题？		-- 继续观察测试

​		还是要早晚重启？不然不太稳定，还是解决稳定性的问题，继续观察



4.检查下数据，股指历史数据补录的		--OK

​		实时发送，批次改成100看是否有延迟, 还是有1-2分钟的延迟

​		修改成500应该没有问题

​		21年的可以发起来



## 20210615

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```





2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

​		保存持仓量，成交量

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[T152_151LOG]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_tme] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


```



今日工作：

20210615

期货主力规则切换算法开发 --明天开始测试

上周夜盘商品数据补录  --ok

实时期货数据检查		--ok



## 20210616

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.72 TB (18.62%)
			35.29 TB (75.32%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？

​		保存持仓量，成交量

​		6.11夜盘数据不应该有， 节假日放假前那个工作日夜盘不开市的 删掉先

建一个新的表：

```
USE [Public1]
GO

/****** Object:  Table [dbo].[futures_main_contract]    Script Date: 2021/6/11 11:25:20 ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO

SET ANSI_PADDING ON
GO

CREATE TABLE [dbo].[futures_main_contract](
	[id] [int] IDENTITY(1,1) NOT NULL,
	[contract_code] [char](10)  NOT NULL,
	[future_variety] [char](10)  NOT NULL,
	[volume] decimal(18, 2) NOT NULL,
	[open_interest] decimal(18, 2) NOT NULL,
	[start_date] [datetime]  NOT NULL,
	[end_date] [datetime]  NOT NULL,
	[update_time] [smalldatetime] NOT NULL,
  PRIMARY KEY CLUSTERED 
(
	[id] ASC
)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
) ON [PRIMARY]

GO

SET ANSI_PADDING OFF
GO


# 查询

select 
id,
contract_code,
future_variety,
volume, 
open_interest,
start_date,
end_date,
update_time
from dbo.futures_main_contract where future_variety = 'IC' AND '2021-06-11' >= start_date AND '2021-06-11' <= end_date;


insert into table dbo.futures_main_contract (contract_code,future_variety,volume, open_interest,start_date,end_date,update_time) values()


新增两个字段：
Volume 成交量
OpenInterest 持仓量

```



thrift2挂了：

bash /usr/local/hbase/bin/restart_thrift2_server.sh



今日工作：

20210616

1.期货主力规则切换程序本地测试和一些逻辑修改



###################

## 20210617

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.73 TB (18.64%)
			35.28 TB (75.29%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33

```



2.期货主力规则切换算法开发

​		是每一个交易日都生成记录还是一段时间？		--ok

​		保存并更新持仓量，成交量		--ok

​		还是从hbase捞出来快一点				--ok

​				filter实现，扫描日k表，按照utim过滤

​		实时的运行起来		--ok

​		历史的先生成， IC, IH, IF		--ok

​			2015-09-03 到2015-09-06都在休息，抗战胜利周年庆，但是节假日里面没有所以导致缺失了2015-09-07的主力合约

​		本地运行起来，测试夜盘数据卡住的问题

todo: 合约品种都改成小写





###################

## 20210618

1.每天上班要做的	

```
1.检查下hadoop集群, hbase集群				--ok
	echo "list" | hbase shell # 是否能列出来
	Hbase  UI页面地址：http://10.10.0.254:60010/master-status#compactStas  # 节点数至少5个， Dead Region Servers
	HDFS   UI页面地址：http://10.10.0.254:50070/dfshealth.html#tab-overview 
			8.73 TB (18.62%)
			35.29 TB (75.31%)
	检查进程， 下面一个都不能少：
		
            2481 HMaster
            18354 ResourceManager
            2180 DataNode
            1925 NameNode
            1845 JournalNode
            28327 Jps
            26696 Main
            30620 QuorumPeerMain
            28238 ThriftServer
jps | wc -l
jps
	
2.检查程序运行和发送情况
10.10.10.104   administrator/Admin123  		--ok
	进程：datacenter-realtime-futures		晚上八点
    	  
10.10.10.102 administrator/Admin711406 
	进程：
	     GuPiaoReduce（RunDataMerge?）	9:25
	     
3.检查界面，行情软件
	# 如果有问题，启动：hbase-daemon.sh start thrift2


CLOSE_WAIT 47
ESTABLISHED 133
FIN_WAIT2 9
TIME_WAIT 33
```

主力合约生成程序开发

​	验证生成的主力代码		--ok

​			日k线插入到数据库中		--ok

​			使用方法:

​				10.10.10.8服务器上的Index_Data_his数据库

​				1.进入Index_Data_his数据库, 将需计算的数据存入“T003_主力合约待计算表”;
​				2、执行“C001_批量计算期指主力合约”存储过程;
​				3、查看“T004_主力合约代码”表

​	生成股指主连数据

​	

跑夜盘数据程序的问题

​		断点看看什么造成的， pass

```
kCycle = (kBuff.TimeStamp - beginOffset - kBreakOffset) / param.cycle; // kBreakOffset不应该是0，已经休息了一夜了


断点：
        // K 线时间点已经历的小节休息时间
        if ((kMod - beginOffset) % _1day >= begin - beginOffset) {
          restTime = param.durations[i].begin - param.durations[i - 1].end;
          if (restTime < _60min * 3) {
            kBreakOffset += restTime;
          }
        }
```



周末吧数据发送2021-01到2021-06的数据发送起来



###################

## 20210619

hashMap 和hashSet， LinkedHashMap

```java
public class HashMap<K,V> extends AbstractMap<K,V>    implements Map<K,V>, Cloneable, Serializable:
// 几个重要的成员变量
/**
   * The default initial capacity - MUST be a power of two.
   * 默认的容量，必须是2的次方：
   * 为了保证每个桶内的元素尽可能均匀的， 对添加的元素进行取模得到下标：h & (length-1)
   * 如果length不是2的次方如：10，假如现在有hash值为11和9，那么进行位运算结果：
   * 1011 & 1001 = 1001， 1001 & 1001 = 1001；
   * 而如果length是2的次方如：16，则同样对hash值为11和9进行取模结果：
   * 1011 & 1111 = 1011， 1001 & 1111 = 1001
   * 这样，有效避免了hash冲突，保证元素尽可能分布均匀
   *
   */
  static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

  /**
   * The maximum capacity, used if a higher value is implicitly specified
   * by either of the constructors with arguments.
   * MUST be a power of two <= 1<<30.
   */
  static final int MAXIMUM_CAPACITY = 1 << 30;

  /**
   * The load factor used when none specified in constructor.
   * 使用hash取模计算下标，元素分布的频率在hash桶中遵循一个泊松分布，然后0.75是泊松分布较理想的参数
   * 上面注释中还给了一个参考例子，当加载因子是0.75是，发生hash碰撞的桶的元素超过8个的概率为0.00000006几乎不可能。
   * 个人觉得从另一角度：
   * 如果加载因子是0.5那么会浪费一半的内存空间，加载因子是1，这样容量满了再去扩容，很容易造成hash冲突，导致链表过程影响查询效率
   * 所以0.75是一个折中的参数。
   */
  static final float DEFAULT_LOAD_FACTOR = 0.75f;

  /**
   *
   * 链表转成红黑树的阈值
   */
  static final int TREEIFY_THRESHOLD = 8;

  /**
   * 红黑树退化成链表的阈值
   */
  static final int UNTREEIFY_THRESHOLD = 6;

  /**
   * 当当前hash表的容量大于这个阈值时，才会进行链表转成红黑树操作
   * 否则只进行resize
   */
  static final int MIN_TREEIFY_CAPACITY = 64;

// put 方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
      boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 先判断是否为空
    if ((tab = table) == null || (n = tab.length) == 0)
      // 如果空就初始化
      n = (tab = resize()).length;
    // 判断插入的地方是否有人了
    if ((p = tab[i = (n - 1) & hash]) == null)
      // 没有人直接在末尾加入新节点
      tab[i] = newNode(hash, key, value, null);
    else {
      // 判断key是否一样
      Node<K,V> e; K k;
      if (p.hash == hash &&
          ((k = p.key) == key || (key != null && key.equals(k))))
        // 一样就就覆盖，更新操作
        e = p;
      // 不一样说明发生了hash碰撞，进一步判断这个桶是链表还是红黑树
      else if (p instanceof TreeNode)
        // 以红黑树方式添加
        e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
      else {
        // 以链表方式添加
        for (int binCount = 0; ; ++binCount) {
          if ((e = p.next) == null) {
            p.next = newNode(hash, key, value, null);
            // 如果链表长度大于阈值，转成红黑树
            if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
              // 里面进一步判断，如果整个表容量小于64就只进行rehash,不转换了
              treeifyBin(tab, hash);
            break;
          }
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            break;
          p = e;
        }
      }
      if (e != null) { // existing mapping for key
        V oldValue = e.value;
        if (!onlyIfAbsent || oldValue == null)
          e.value = value;
        afterNodeAccess(e);
        // 如果是覆盖就返回老的值
        return oldValue;
      }
    }
    // 最后添加完，判断是否需要resize
    ++modCount;
    if (++size > threshold)
      resize(); // 先扩容现容量的2倍，重新放置元素
    // 为了继承HashMap的LinkedHashMap类服务的
    afterNodeInsertion(evict);
    return null;
  }


// get 方法
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
      // 判断下标位置第一个元素是否符合key
      if (first.hash == hash && // always check first node
          ((k = first.key) == key || (key != null && key.equals(k))))
        // 是就返回第一个
        return first;
      if ((e = first.next) != null) {
        // 不是就接着往下找，判断桶如果是红黑树就用红黑树方式找，如果是链表就按链表找
        if (first instanceof TreeNode)
          return ((TreeNode<K,V>)first).getTreeNode(hash, key);
        do {
          if (e.hash == hash &&
              ((k = e.key) == key || (key != null && key.equals(k))))
            return e;
        } while ((e = e.next) != null);
      }
    }
    return null;
  }

public class LinkedHashMap<K,V>     extends HashMap<K,V>     implements Map<K,V>
    
 // 使用双向链表和重写了hashMap中3个方法保证顺序：
    // Callbacks to allow LinkedHashMap post-actions
    void afterNodeAccess(Node<K,V> p) { }
    void afterNodeInsertion(boolean evict) { }
    void afterNodeRemoval(Node<K,V> p) { }
    
 // put 方法： put方法没有重写HashMap的put方法，但是重新了其中的几个子的方法：
   Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
    LinkedHashMap.Entry<K,V> p =
        new LinkedHashMap.Entry<K,V>(hash, key, value, e);
    linkNodeLast(p);    // 加到双向链表的末尾
    return p;
  }

void afterNodeAccess(Node<K,V> e) { // move node to last将访问的元素放到链表最后
    
void afterNodeInsertion(boolean evict) { // possibly remove eldest， evict：是否删除旧元素
  LinkedHashMap.Entry<K,V> first;
    // removeEldestEntry给实现者来重写，有机会删除最老的元素，保持一定容量
  if (evict && (first = head) != null && removeEldestEntry(first)) { // removeEldestEntry：return false;
    K key = first.key;
    removeNode(hash(key), key, null, false, true);
  }
}
void afterNodeRemoval(Node<K,V> e) { // unlink remove方法中调用，删除链表中的元素
    
// 重写了get方法：
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
      return null;
    if (accessOrder) // 如果accessOrder为true,则开启LRU策略
      afterNodeAccess(e);
    return e.value;
  }
```

ConcurrentHashMap





```


Collection:
	List:
		ArrayList
		LinkedList
	Set:
		HashSet
		TreeSet
	Queue:
		LinkedBlockingQueue
		
Map:
	HashMap
		1.7: 数组+链表， 头插法
		1.8：数组+链表+红黑树， 尾插法
		扩容机制，默认0.75
		capacity必须是2的幂
		equals和hashCode必须同时重写
	ConcurrentHashMap
	LinkedHashMap
	
	
	
	并发：
	线程之间如何通信：
	实现一个生产者和消费者模型
	synchronized:
		对象：
			对象头：
				Mark Word, 存储对象的HashCode,锁标志和分代年龄
				Class Pointer,对象指向它的类元数据的指针，虚拟机通过这个指针来确定对象是哪个类的实例
				Monitor:
					EntryList
					Owner,指向持有Monitor对象的线程
					WaitSet
			实例数据
			对其填充
		使用：
			代码块：锁住的是括号内的对象， 通过monitorenter和monitorexit锁对象，程序计数器count
			方法上：锁住的是当前调用对象,ACC_SYNCHRONIZED
			静态方法：这个类对象，而不是实例对象
		锁升级过程：偏向锁 -> 轻量级锁（乐观锁） -> 重量级锁
	ThreadLocal
		实现
		get
		put
		内存泄露
		InheritableThreadLocal
		用来解决什么问题，为什么使用
	volatile: TODO

	JUC:
    	Lock
    	CountDownLatch
    	CyclicBarrier
    	TODO:
		
	线程池：
		4种线程池：
			CachedThreadPool
			FixedThreadPool
			SingleThreadPool
			ScheduledThreadPool
		7个参数：
			corePoolSize
			maximumPoolSize
			keepAliveTime
			TimeUnit
			workQueue
			threadFactory
			RejectedExecutionHandler
		如何优雅的指定线程名字
		阿里不建议newCachedThreadPool等方法，建议自己构造原因
		工厂方法
		创建线程几种方式
		线程池运行原理
			状态
			TODO
		使用场景
		怎么尽可能提高多线程并发数
		
		
	
	JVM:
	io
	反射
	
数据库和中间件
	mysql
	zookeeper
	kafka
	redis
	
大数据：
	hadoop:
		hdfs
		mapreduce
		hbase
		yarn
		hive
	spark
		spark core
		spark sql
	flink
		
计算机基础，数据结构和算法
	设计模式
	计算机基础
	数据结构
	算法
```



flink



todo:


    hbase优化：
    1.生产环境下关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。
    一般生产环境下为了避免影响读写请求，会禁用自动触发major compaction。
    2.使用数据块编码


补k线程序有个小bug,kbug:11:29:59 , tick:13:00:01,那就会漏掉13:00:00的k线



学习搭建和使用hive

hbase 版本：1.3.1

hadoop版本：2.7.3





3.归并排序？

​	Blockingqueue



todo:

nagios

新的项目架构：

​	kafka + redis + flink + hbase

学习：

​	hive + spark + hadoop

源码：

​	kafka, hbase

SPI ,serviceLoader

hbase性能测试，吞吐量如何？

用flink去实现k线合并的程序

装一套hive,跟hbase集成

装一套监控的系统

看看：

开仓，平仓

盘面资金

大单数据

北向资金

策略

主力合约Tick数据

股指

期权

股票的开盘时间

主连

股票



代码问题：

​	日志问题，直接System.println.out

​	配置文件，ip端口直接写死的

​	打出来的jar包是用eclipse导出来的，应该用mvn install

​	依赖的jar包直接提交了

​	代码格式化问题，格式太乱，大量重复代码，没有用到的变量。

​	单元测试



## TODO



LinkedBlockingQueue 线程安全

算法和计算机原理

flink

clickhouse

mysql

数据仓库








​	